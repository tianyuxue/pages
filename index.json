[{"content":" 本文介绍了如何在自定义控制器中实现OpenFlow Nicira扩展协议\n 在开发自定义SDN控制器的过程中，如果要向Open vSwitch下发下面的一条流表：\n1  ovs-ofctl -O openflow13 add-flow br-int \u0026#34;cookie=0xa,table=20,priority=300,in_port=\u0026#34;vxlan\u0026#34;,udp,nw_dst=\u0026#34;100.95.0.1\u0026#34;,tp_dst=53 actions=move:NXM_NX_TUN_IPV4_SRC[]-\u0026gt;NXM_NX_REG0[],move:NXM_NX_TUN_ID[0..23]-\u0026gt;NXM_NX_REG1[0..23],goto_table:40\u0026#34;   就需要构造出符合Openflow协议的二进制数据。通常Openflow相关的library会提供面向开发者友好的构造方法，比如OpenDayLight Openflow Plugin中就用yang生成了可以直接使用的类以及相关的序列化、反序列化方法，基本的Openflow消息格式可以简单的生成，但是有一些Openflow扩展协议，就需要分析协议内容。下面以上面流表为例，分析一下这个过程。\n1. 查看ovs文档 上面流表中的action使用了move指令，首先从ovs入手，查看帮助文档man ovs-actions的move部分：\n可看到，move指令是OpenFlow1.3的一个扩展。\n2. 查看Openflow 1.3扩展文档 从官网查询，copy field指令属于扩展ext-320, 从协议文档中可以查到move指令的基本格式：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  /* Action structure for ONFACT_ET_COPY_FIELD. */ struct onf_act_copy_field { \tuint16_t type; /* OFPAT_EXPERIMENTER. */ \tuint16_t len; /* Length is padded to 64 bits. */ \tuint32_t experimenter; /* ONF_EXPERIMENTER_ID. */ \tuint16_t exp_type; /* ONFACT_ET_COPY_FIELD. */ \tuint8_t pad2[2]; \tuint16_t n_bits; /* Number of bits to copy. */ \tuint16_t src_offset; /* Starting bit offset in source. */ \tuint16_t dst_offset; /* Starting bit offset in destination. */ \tuint8_t pad[2]; /* Align to 32 bits. */ \t/* Followed by: * - Exactly 8, 12 or 16 bytes containing the oxm_ids, then * - Enough all-zero bytes (either 0 or 4) to make the action a whole * multiple of 8 bytes in length */ \tuint32_t oxm_ids[0]; /* Source and destination OXM headers */ }; OFP_ASSERT(sizeof(struct ofp_action_copy_field) == 20);   以ODL为例，控制器提供的序列化方法也跟上述协议对应：\n1 2 3 4 5 6 7 8 9 10 11 12   @Override  public void serialize(final Action input, final ByteBuf outBuffer) {  ActionRegMove actionRegMove = (ActionRegMove) input.getActionChoice();  final int startIndex = outBuffer.writerIndex();  serializeHeader(EncodeConstants.EMPTY_LENGTH, SUBTYPE, outBuffer);  outBuffer.writeShort(actionRegMove.getNxActionRegMove().getNBits().toJava());  outBuffer.writeShort(actionRegMove.getNxActionRegMove().getSrcOfs().toJava());  outBuffer.writeShort(actionRegMove.getNxActionRegMove().getDstOfs().toJava());  writeNxmHeader(actionRegMove.getNxActionRegMove().getSrc(), outBuffer);  writeNxmHeader(actionRegMove.getNxActionRegMove().getDst(), outBuffer);  writePaddingAndSetLength(outBuffer, startIndex);  }   其中：\n nbits是move的位数 srcOfs是源地址中，copy起始位置 dstOfs是目的地址中，copy的其实位置 oxm_ids是源和目的的两个field引用  现在问题是oxm_ids该用什么值？\n3. Nicira 扩展中的filed名称 Openvswitch标准文档中有描述filed的TLV格式，以及标准协议中不同field的值：\n如果是标准协议中的field，可以直接参考。但是上述流表用了NXM_*开头的field， 这属于nicira扩展，该扩展的信息目前并没有详细的文档。为此，只能在开源的已实现的控制器中寻找标准。\nryu是一个支持Openflow协议的开源控制器（其实主要是比ovs的c代码便于阅读），其代码 ryu/ofproto/nicira_ext.py中定义了nicira扩展的field标准：\n1 2 3 4 5 6 7 8  ... NXM_NX_TUN_ID = nxm_header(0x0001, 16, 8) NXM_NX_TUN_ID_W = nxm_header_w(0x0001, 16, 8) NXM_NX_TUN_IPV4_SRC = nxm_header(0x0001, 31, 4) NXM_NX_TUN_IPV4_SRC_W = nxm_header_w(0x0001, 31, 4) NXM_NX_TUN_IPV4_DST = nxm_header(0x0001, 32, 4) NXM_NX_TUN_IPV4_DST_W = nxm_header_w(0x0001, 32, 4) ...   上面以_w结尾的field，就是带mask的field。并且ryu代码中有field值的计算方式：\n1 2 3 4 5 6 7 8  def nxm_header__(vendor, field, hasmask, length): \treturn (vendor \u0026lt;\u0026lt; 16) | (field \u0026lt;\u0026lt; 9) | (hasmask \u0026lt;\u0026lt; 8) | length  def nxm_header(vendor, field, length):  return nxm_header__(vendor, field, 0, length)  def nxm_header_w(vendor, field, length):  return nxm_header__(vendor, field, 1, (length) * 2)   自此，我们可以根据ryu的源码，分析出Nicira扩展中的field的值。\n4 总结 上面通过了一个ovs流表，展示了自定义SDN控制器下发流表时的不确定字段分析方法。\n","permalink":"https://tianyuxue.github.io/posts/ovs-learning-2/","summary":"\u003cblockquote\u003e\n\u003cp\u003e本文介绍了如何在自定义控制器中实现OpenFlow Nicira扩展协议\u003c/p\u003e\n\u003c/blockquote\u003e","title":"Open vSwitch学习 - 2 关于OpenFlow Nicira扩展协议的一些解释"},{"content":" 本文介绍了OVS的基本功能以及开发环境搭建的过程\n 1 基本功能 ovs是一个分层的软件交换机，支持vlan、网卡bond、限速、vxlan隧道等功能、支持openflow1.0+协议，提供数据面高性能的转发功能。从部署视图看，进程结构如下：\n  ovs-vswitchd 守护进程：\n 实现了交换机的功能，包含了支持流表转发的内核模块    ovsdb-server 进程：\n 保存ovs配置的轻量级数据库    ovs-dpctl：\n 配置ovs内核模块的命令行工具    ovs-vsctl：\n 查询、修改 ovs-vswitchd配置的命令行工具    ovs-appctl：\n 控制 ovs-vswitchd 进程启动、停止的命令行工具    ovs-ofctl：\n 查询修改流表的命令行工具    除了以上进程，还有几个不常用的工具：\n  ovs-pki 管理系统证书的工具\n  ovs-testcontroller 用于开发，测试环境的使用sdn控制器\n  支持流表解析的tcpdump工具\n    2 为什么要使用 ovs 虚拟化环境下，Hypervisors 需要二层Bridge功能将同一宿主机上的VM流量转发，目前Linux Bridge功能已经稳定完善，但是对于多宿主机之间VM迁移，网络状态变更支持不够完善，针对这些问题，ovs提供了下列功能：\n 快速响应网络环境变更 数据面可以集成专用的硬件芯片，做到线性转发  3 开发环境搭建 以Ubuntu20.04为例，从源码编译ovs的过程如下：\n step1 下载源码  1 2  git clone https://github.com/openvswitch/ovs.git git checkout v2.7.0   step2 安装必须的软件  1  apt install autoconf libtool   step3 编译安装  1 2 3 4  ./boot.sh ./configure make make install   step4 加载内核模块  1  /sbin/modprobe openvswitch   step5 启动ovs守护进程  1 2  export PATH=$PATH:/usr/local/share/openvswitch/scripts ovs-ctl start   ","permalink":"https://tianyuxue.github.io/posts/ovs-learing-1/","summary":"\u003cblockquote\u003e\n\u003cp\u003e本文介绍了OVS的基本功能以及开发环境搭建的过程\u003c/p\u003e\n\u003c/blockquote\u003e","title":"Open vSwitch学习 - 1 开发环境搭建"},{"content":" 本文的讨论基于Kratos v1.0.x版本\n Kratos是bilibili开源的一套Go微服务框架，包含大量微服务相关框架及工具，本文主要从源码角度分析一下Kratos中与缓存相关的代码，在分析的过程中，我会从Kratos提供的不同的功能点来结合自己的一些理解进行阐述。\n1 核心对象的分析 Kratos http模块叫做blademaster，其主要设计参考了借鉴Gin的代码。整个http 模块可以拆分如下3个部分：\n图 1 blademaster模块架构\n Router对象借鉴了Gin的设计，使用Radix Tree存储了全部的路由信息 Context封装了一个http请求相关的所有上下文信息，Context的存在统一了Handler的接口 Handlers对象是职责链模式的实现，用于处理http请求。对于每一个请求，有一串handler依次处理，一个handler处理成功后可以交给下一个，也可以根据情况直接将http响应返回给客户端。这三个组件的交互见下图：  图 2 blademaster组件交互图\nKratos使用struct Engine封装了上面3个对象，Engine对象的定义如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40  type Engine struct { \tRouterGroup // 用于注册路由信息  \tlock sync.RWMutex \tconf *ServerConfig // 配置信息  \taddress string // 服务地址  \ttrees methodTrees // 基数树存储路由信息 \tserver atomic.Value // store *http.Server \tmetastore map[string]map[string]interface{} // metastore is the path as key and the metadata of this path as value, it export via /metadata  \tpcLock sync.RWMutex \tmethodConfigs map[string]*MethodConfig  \tinjections []injection  \t// If enabled, the url.RawPath will be used to find parameters. \tUseRawPath bool  \t// If true, the path value will be unescaped. \t// If UseRawPath is false (by default), the UnescapePathValues effectively is true, \t// as url.Path gonna be used, which is already unescaped. \tUnescapePathValues bool  \t// If enabled, the router checks if another method is allowed for the \t// current route, if the current request can not be routed. \t// If this is the case, the request is answered with \u0026#39;Method Not Allowed\u0026#39; \t// and HTTP status code 405. \t// If no other Method is allowed, the request is delegated to the NotFound \t// handler. \tHandleMethodNotAllowed bool  \tallNoRoute []HandlerFunc \tallNoMethod []HandlerFunc \tnoRoute []HandlerFunc \tnoMethod []HandlerFunc  \tpool sync.Pool // Context池，复用Context对象，减少GC压力 }   每一个Context对象中保存了它所需要的Handler，Context对象的定义如下:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  type Context struct { \tcontext.Context // 提供golang标准context的接口  \tRequest *http.Request // http请求的内存对象 \tWriter http.ResponseWriter // http响应的内存对象  \t// flow control \tindex int8 //当前执行到了第几个handler \thandlers []HandlerFunc //所有需要执行的handler  \t// Keys is a key/value pair exclusively for the context of each request. \tKeys map[string]interface{} \t// This mutex protect Keys map \tkeysMutex sync.RWMutex  \tError error  \tmethod string \tengine *Engine  \tRoutePath string  \tParams Params }   这样通过这Context + Handler，通过职责链模式提供了很高的代码扩展性，尤其契合Http请求处理这种场景。下面具体探讨下Http服务器需要重点关注的一些内容：\n IO模型 路由信息的处理  1.1 IO模型 blademaster直接使用了golang官方的http.Server包。在Engine对象的启动代码Run()方法可以看到：\n1 2 3 4 5 6 7 8 9 10 11 12  func (engine *Engine) Run(addr ...string) (err error) { \taddress := resolveAddress(addr) \tserver := \u0026amp;http.Server{ \tAddr: address, \tHandler: engine, \t} \tengine.server.Store(server) \tif err = server.ListenAndServe(); err != nil { \terr = errors.Wrapf(err, \u0026#34;addrs: %v\u0026#34;, addr) \t} \treturn }   代码中启动了http.Server，在Engine.ServeHttp()方法（代码如下）中可以看到，Engine接管了所有的http请求，每当请求到来时候，就从Context Pool中获取一个Context对象，处理完毕后归还到Context Pool中。\n1 2 3 4 5 6 7 8 9 10  // ServeHTTP conforms to the http.Handler interface. func (engine *Engine) ServeHTTP(w http.ResponseWriter, req *http.Request) { \tc := engine.pool.Get().(*Context) \tc.Request = req \tc.Writer = w \tc.reset()  \tengine.handleContext(c) \tengine.pool.Put(c) }   这样就能看出blademaster并未实现自己的线程模型，完全使用了官方http包中一个连接一个goroutine的线程模型，所有处理连接的goroutine会调用阻塞式的读写方法，一旦数据未准备好，就会进入阻塞状态，数据到达后由netpoller唤醒阻塞的goroutine进行处理，因此，Kratos 的http线程模型可以视为单Reactor多线程模式。\n1.2 路由信息的存储 在Http服务器处理业务请求的时候，查询最多的就是路由信息了，一个大型应用可能会注册很多路由信息，在高并发下被大量查询，因此其查询效率非常重要。众所周知，哈希表的O(1)查询效率当然是最快的，将所有路由信息存储到hash表里能解决问题么？如果路由信息都是常量，这样是最简单的方式。但是路由信息中还存在很多参数，尤其在restful风格的接口设计中，因此blademaster或者说是Gin采用了基数树这个数据结构来存储。\n在blademaster的代码中，每一个Http方法，比如GET、POST方法，其路由信息存储在一个基数树中，所有Http方法的路由信息构成了一个森林，存储在Engine结构体的methodTrees对象中。树中每一个节点的定义如下：\n1 2 3 4 5 6 7 8 9 10  type node struct { \tpath string // 存储的路径 \tindices string \tchildren []*node // 孩子节点 \thandlers []HandlerFunc // 该路径的处理函数 \tpriority uint32 \tnType nodeType // 节点类型 \tmaxParams uint8 \twildChild bool // 是否是含有url参数的节点 }   通过基数树这种数据结构，解决了带参数URL的查询效率问题。具体的基数树的代码过于细节，本文主要讨论blademaster的实现，这里就不再深入，后续我计划专门写一篇文章来理解基数树在Gin中的使用。\n2 部分常用业务功能的实现 2.1 CORS CORS用来支持浏览器跨域请求，Kratos的http模块提供了支持CORS的方法，其核心功能很简单：\n 预先配置允许跨域访问的地址 当CORS请求到达之后，验证与配置的地址是否匹配 验证成功后返回特定的Http Header给客户端，否则返回错误信息  Kratos通过传入地址数组创建出CORS middleware，创建代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39  // CORS returns the location middleware with default configuration. // 传入允许访问的跨域地址 func CORS(allowOriginHosts []string) HandlerFunc { \tconfig := \u0026amp;CORSConfig{ \tAllowMethods: []string{\u0026#34;GET\u0026#34;, \u0026#34;POST\u0026#34;}, \tAllowHeaders: []string{\u0026#34;Origin\u0026#34;, \u0026#34;Content-Length\u0026#34;, \u0026#34;Content-Type\u0026#34;}, \tAllowCredentials: true, \tMaxAge: time.Duration(0), \tAllowOriginFunc: func(origin string) bool { \tfor _, host := range allowOriginHosts { \tif strings.HasSuffix(strings.ToLower(origin), host) { \treturn true \t} \t} \treturn false \t}, \t} \treturn newCORS(config) }  // newCORS returns the location middleware with user-defined custom configuration. // 返回cors middleware func newCORS(config *CORSConfig) HandlerFunc { \tif err := config.Validate(); err != nil { \tpanic(err.Error()) \t} \tcors := \u0026amp;cors{ \tallowOriginFunc: config.AllowOriginFunc, \tallowAllOrigins: config.AllowAllOrigins, \tallowCredentials: config.AllowCredentials, \tallowOrigins: normalize(config.AllowOrigins), \tnormalHeaders: generateNormalHeaders(config), \tpreflightHeaders: generatePreflightHeaders(config), \t}  \treturn func(c *Context) { \tcors.applyCORS(c) \t} }   cors.applyCORS() 方法中实现CORS的验证逻辑，代码如下，具体细节可以参考注释。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29  func (cors *cors) applyCORS(c *Context) { \torigin := c.Request.Header.Get(\u0026#34;Origin\u0026#34;) \t// 通过http header中的orgin判断是否是跨域请求 \tif len(origin) == 0 { \t// request is not a CORS request \treturn \t} \t// 通过当前请求域名与允许的域名匹配 \tif !cors.validateOrigin(origin) { \tlog.V(5).Info(\u0026#34;The request\u0026#39;s Origin header `%s` does not match any of allowed origins.\u0026#34;, origin) \t// 如果不匹配，就返回403状态码 \tc.AbortWithStatus(http.StatusForbidden) \treturn \t}  \t// 对于OPTIONS请求进行特殊处理 \tif c.Request.Method == \u0026#34;OPTIONS\u0026#34; { \tcors.handlePreflight(c) \tdefer c.AbortWithStatus(200) \t} else { \t// http响应的header中添加CORS相关的header \tcors.handleNormal(c) \t}  \tif !cors.allowAllOrigins { \theader := c.Writer.Header() \theader.Set(\u0026#34;Access-Control-Allow-Origin\u0026#34;, origin) \t} }   2.2 CSRF CSRF指的是跨站请求伪造攻击，通常造成影响较为严重。对CSRF的防护手段主要是，当表单展示的时候，在表单中增加验证的token，当表单提交后也带这这个token来确保这个表单提交不是伪造的。\nKratos对CSRF的防护做的很基础，只是检查了Http Header中的Referer字段是否合法，代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46  // CSRF returns the csrf middleware to prevent invalid cross site request. // Only referer is checked currently. func CSRF(allowHosts []string, allowPattern []string) HandlerFunc { \tvalidations := []func(*url.URL) bool{}  \taddHostSuffix := func(suffix string) { \tvalidations = append(validations, matchHostSuffix(suffix)) \t} \taddPattern := func(pattern string) { \tvalidations = append(validations, matchPattern(regexp.MustCompile(pattern))) \t}  \tfor _, r := range allowHosts { \taddHostSuffix(r) \t} \tfor _, p := range allowPattern { \taddPattern(p) \t}  \treturn func(c *Context) { \t// 获取Header中的Refer字段 \treferer := c.Request.Header.Get(\u0026#34;Referer\u0026#34;) \tif referer == \u0026#34;\u0026#34; { \tlog.V(5).Info(\u0026#34;The request\u0026#39;s Referer or Origin header is empty.\u0026#34;) \tc.AbortWithStatus(403) \treturn \t} \tillegal := true  \t// 校验是否符合预定义的地址 \tif uri, err := url.Parse(referer); err == nil \u0026amp;\u0026amp; uri.Host != \u0026#34;\u0026#34; { \tfor _, validate := range validations { \tif validate(uri) { \tillegal = false \tbreak \t} \t} \t} \tif illegal { \tlog.V(5).Info(\u0026#34;The request\u0026#39;s Referer header `%s` does not match any of allowed referers.\u0026#34;, referer) \t// 不符合返回403 \tc.AbortWithStatus(403) \treturn \t} \t} }   对于需要严格防护CSRF攻击的场景，还需要使用其他第三方的库，或者自己实现解决方案。\n2.3 限流 kratos 借鉴了 Sentinel 项目的自适应限流系统，通过综合分析服务的 cpu 使用率、请求成功的 qps 和请求成功的 rt 来做自适应限流保护。这篇文章只讨论http模块，具体的限流算法我会另外选择文章来讨论。Kratos也将限流功能以中间件方式实现：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  // Limit return a bm handler func. func (b *RateLimiter) Limit() HandlerFunc { \treturn func(c *Context) { \turi := fmt.Sprintf(\u0026#34;%s://%s%s\u0026#34;, c.Request.URL.Scheme, c.Request.Host, c.Request.URL.Path) \tlimiter := b.group.Get(uri) \t// 执行限流 \tdone, err := limiter.Allow(c) \tif err != nil { // 流量被限制后返回错误 \t_metricServerBBR.Inc(uri, c.Request.Method) \tc.JSON(nil, err) \tc.Abort() \treturn \t} \t// 成功处理后更新统计信息，作为后续限流依据 \tdefer func() { \tdone(limit.DoneInfo{Op: limit.Success}) \tb.printStats(uri, limiter) \t}() \tc.Next() \t} }   可以看出，中间件的抽象有助于代码的扩展，可以根据项目情况灵活的选用不同的限流方式。\n2.4 日志 blademaster中的日志功能与其他框架类似，提供了http请求相关信息的记录，Log中间件的具体代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63  // Logger is logger middleware func Logger() HandlerFunc { \tconst noUser = \u0026#34;no_user\u0026#34; \treturn func(c *Context) { \t// 获取执行剩余handler前的信息 \tnow := time.Now() \treq := c.Request \tpath := req.URL.Path \tparams := req.Form \tvar quota float64 \tif deadline, ok := c.Context.Deadline(); ok { \tquota = time.Until(deadline).Seconds() \t} \t// 执行剩余handler \tc.Next()  \t// 获取handler执行完毕后的信息 \terr := c.Error \tcerr := ecode.Cause(err) \t// 请求处理的时间 \tdt := time.Since(now) \tcaller := metadata.String(c, metadata.Caller) \tif caller == \u0026#34;\u0026#34; { \tcaller = noUser \t}  \tif len(c.RoutePath) \u0026gt; 0 { \t_metricServerReqCodeTotal.Inc(c.RoutePath[1:], caller, req.Method, strconv.FormatInt(int64(cerr.Code()), 10)) \t_metricServerReqDur.Observe(int64(dt/time.Millisecond), c.RoutePath[1:], caller, req.Method) \t}  \tlf := log.Infov \terrmsg := \u0026#34;\u0026#34; \tisSlow := dt \u0026gt;= (time.Millisecond * 500) \t// 通过是否有错误和处理时间是否过长来决定是不是使用warn级别的日志输出 \tif err != nil { \terrmsg = err.Error() \tlf = log.Errorv \tif cerr.Code() \u0026gt; 0 { \tlf = log.Warnv \t} \t} else { \tif isSlow { \tlf = log.Warnv \t} \t} \t// 记录日志 \tlf(c, \tlog.KVString(\u0026#34;method\u0026#34;, req.Method), \tlog.KVString(\u0026#34;ip\u0026#34;, c.RemoteIP()), \tlog.KVString(\u0026#34;user\u0026#34;, caller), \tlog.KVString(\u0026#34;path\u0026#34;, path), \tlog.KVString(\u0026#34;params\u0026#34;, params.Encode()), \tlog.KVInt(\u0026#34;ret\u0026#34;, cerr.Code()), \tlog.KVString(\u0026#34;msg\u0026#34;, cerr.Message()), \tlog.KVString(\u0026#34;stack\u0026#34;, fmt.Sprintf(\u0026#34;%+v\u0026#34;, err)), \tlog.KVString(\u0026#34;err\u0026#34;, errmsg), \tlog.KVFloat64(\u0026#34;timeout_quota\u0026#34;, quota), \tlog.KVFloat64(\u0026#34;ts\u0026#34;, dt.Seconds()), \tlog.KVString(\u0026#34;source\u0026#34;, \u0026#34;http-access-log\u0026#34;), \t) \t} }   这个方法在handler开始处理前后记录时间，用户等想关元信息，根据处理结果是否出错以及处理时间是否过长来决定日志的输出级别。\n2.5 Trace blademaster中Trace信息的记录方式同日志信息一样，其实现代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32  // Trace is trace middleware func Trace() HandlerFunc { \treturn func(c *Context) { \t// 从http request header 中获取trace信息 \tt, err := trace.Extract(trace.HTTPFormat, c.Request.Header) \tif err != nil { \tvar opts []trace.Option \tif ok, _ := strconv.ParseBool(trace.KratosTraceDebug); ok { \topts = append(opts, trace.EnableDebug()) \t} \t// 如果trace 信息不存在，就根据当前url创建一个trace单元 \tt = trace.New(c.Request.URL.Path, opts...) \t} \t// 设定trace信息 包含标题和tag \tt.SetTitle(c.Request.URL.Path) \tt.SetTag(trace.String(trace.TagComponent, _defaultComponentName)) \tt.SetTag(trace.String(trace.TagHTTPMethod, c.Request.Method)) \tt.SetTag(trace.String(trace.TagHTTPURL, c.Request.URL.String())) \tt.SetTag(trace.String(trace.TagSpanKind, \u0026#34;server\u0026#34;)) \t// business tag \tt.SetTag(trace.String(\u0026#34;caller\u0026#34;, metadata.String(c.Context, metadata.Caller)))  \t// 把trace信息加入到http header中，让用户可以查看，便于debug，同时也让下游代码可以继续记录trace信息 \tc.Writer.Header().Set(trace.KratosTraceID, t.TraceID()) \t// 根据trace信息，新建一个官方包里的context \tc.Context = trace.NewContext(c.Context, t) \t// 调用剩余的handler \tc.Next() \t// 标记trace信息已经完成 \tt.Finish(\u0026amp;c.Error) \t} }   要记录trace信息，blademaster首先尝试从当前http request header中获取已经存在trace信息，如果trace信息不存在，说明这是链路调用的开始，就依据当前请求信息新建一个Trace单元。同样的，在handler执行前后，记录相关信息到trace单元中，然后将trace信息存放在http response header中，方便下游系统处理。trace信息中比较关键的要素有：\n trace id url地址 业务模块相关的信息 处理结果信息  2.6 Recovery 上面已经讨论过，blademaster使用的一个请求一个goroutine的IO模型，如果goroutine出现panic怎么办？这时候u需要把错误信息传递给调用方，但是panic会导致整个进程挂掉，这显然是不合理的，blademaster的recovery中间件就是用来将panic信息转化为http 500的错误信息，即保证进程运行，也把错误信息返回给客户端，类似于Spring中的Global Exception Handler。其实现代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  // Recovery returns a middleware that recovers from any panics and writes a 500 if there was one. func Recovery() HandlerFunc { \treturn func(c *Context) { \t// 通过defer方法从panic中恢复 \tdefer func() { \tvar rawReq []byte \tif err := recover(); err != nil { \tconst size = 64 \u0026lt;\u0026lt; 10 \tbuf := make([]byte, size) \t// 获取出错的栈帧信息 \tbuf = buf[:runtime.Stack(buf, false)] \t// 获取出错的http请求的详细信息 \tif c.Request != nil { \trawReq, _ = httputil.DumpRequest(c.Request, false) \t} \tpl := fmt.Sprintf(\u0026#34;http call panic: %sn%vn%sn\u0026#34;, string(rawReq), err, buf) \tfmt.Fprintf(os.Stderr, pl) \t// 记录错误日志 \tlog.Error(pl) \t// 返回500错误信息 \tc.AbortWithStatus(500) \t} \t}() \tc.Next() \t} }   从上述代码中可以看到，Recovery中间件recovery()函数从panic中恢复，并返回给客户端错误信息，这也意味着Recovery中间件应该放在所有中间件的最前面。\n3 总结 本文讨论kratos blademaster模块的一些实现细节，可以看出，得益与职责链模式的使用，中间件的扩展非常灵活。\n","permalink":"https://tianyuxue.github.io/posts/kratos-src-http/","summary":"\u003cblockquote\u003e\n\u003cp\u003e本文的讨论基于Kratos v1.0.x版本\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eKratos是bilibili开源的一套Go微服务框架，包含大量微服务相关框架及工具，本文主要从源码角度分析一下Kratos中与缓存相关的代码，在分析的过程中，我会从Kratos提供的不同的功能点来结合自己的一些理解进行阐述。\u003c/p\u003e","title":"Kratos源码分析 - http部分"},{"content":" 本文的讨论基于Kratos v1.0.x版本\n Kratos是bilibili开源的一套Go微服务框架，包含大量微服务相关框架及工具，本文主要从源码角度分析一下Kratos中与缓存相关的代码，在分析的过程中，我会从Kratos提供的不同的功能点来结合自己的一些理解进行阐述（这篇文章没有复杂的原理，只有从工程角度的一些最佳实践)。\n1 Kratos缓存部分提供的功能 Kratos提供了缓存相关的常用功能，见下表：\n 使用空缓存避免缓存穿透 缓存失效后，回源请求支持分批获取数据库数据，减少数据库访问延时 异步添加缓存 监控缓存回源比 缓存失效后，通过singleflight模式限制回源访问数据库的并发度，避免数据库压力过大  2 代码实现 Kratos提供了kratos tool genbts生成缓存回源代码，并且提供了一些配置，下面根据Kratos源码提供的示例代码进行分析，代码位于tool/kartos-gen-bts/test-data/dao.bts.go文件中的Demos()方法，具体含义可以参考代码中的注释：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87  // Demos get data from cache if miss will call source method, then add to cache. func (d *dao) Demos(c context.Context, keys []int64) (res map[int64]*Demo, err error) { \tif len(keys) == 0 { \treturn \t} \taddCache := true  // 首先尝试从缓存中加载数据 \tif res, err = d.CacheDemos(c, keys); err != nil { \taddCache = false \tres = nil \terr = nil \t}  // miss 用来存储缓存未命中的数据 \tvar miss []int64 \tfor _, key := range keys { \tif (res == nil) || (res[key] == nil) { \tmiss = append(miss, key) \t} \t}  // 统计缓存命中数量 \tcache.MetricHits.Add(float64(len(keys)-len(miss)), \u0026#34;bts:Demos\u0026#34;)  \tfor k, v := range res { \tif v.ID == -1 { \tdelete(res, k) \t} \t} \tmissLen := len(miss) \tif missLen == 0 { \treturn \t} \tmissData := make(map[int64]*Demo, missLen)  // 统计缓存未命中的数量  cache.MetricMisses.Add(float64(missLen), \u0026#34;bts:Demos\u0026#34;) \tvar mutex sync.Mutex   // 通过errgroup包，分批从数据库中执行回源，请求数据量大的的情况下可以降低延迟 \tgroup := errgroup.WithCancel(c) \tif missLen \u0026gt; 20 { \tgroup.GOMAXPROCS(20) \t} \tvar run = func(ms []int64) { \tgroup.Go(func(ctx context.Context) (err error) { \tdata, err := d.RawDemos(ctx, ms) \tmutex.Lock() \tfor k, v := range data { \tmissData[k] = v \t} \tmutex.Unlock() \treturn \t}) \t} \tvar ( \ti int \tn = missLen / 2 \t) \tfor i = 0; i \u0026lt; n; i++ { \trun(miss[i*2 : (i+1)*2]) \t} \tif len(miss[i*2:]) \u0026gt; 0 { \trun(miss[i*2:]) \t} \terr = group.Wait() \tif res == nil { \tres = make(map[int64]*Demo, len(keys)) \t} \tfor k, v := range missData { \tres[k] = v \t} \tif err != nil { \treturn \t}  // 数据库中不存在的数据也在缓存中存储一份默认值 \tfor _, key := range miss { \tif res[key] == nil { \tmissData[key] = \u0026amp;Demo{ID: -1} \t} \t} \tif !addCache { \treturn \t}  // 通过异步的方法添加缓存，减少本次请求的延迟 \td.cache.Do(c, func(c context.Context) { \td.AddCacheDemos(c, missData) \t}) \treturn }   2.1 缓存穿透 缓存穿透指的是，在读数据的时候，没有命中缓存，请求“穿透”了缓存，直接访问后端数据库的情况。缓存穿透的情况下，缓存没有发挥作用，业务系统虽然去缓存查询数据，但缓存中没有数据，因此导致了业务系统需要再次去存储系统查询数据。通常不存在的数据访问应该不会太多，但是如果针对不存在数据进行大量恶意访问，就会导致这些请求全部被数据库处理，情况严重的话会造成整个业务系统不可用。这种情况的解决方案是，对于不存在的请求，也在缓存中存放一份表示不存在的数据，Kratos的代码中也是这样实现的。\nKrato tool genbts 工具提供了配置项-nullcache来避免缓存穿透，配置了之后，生成的代码中会在回源之后增加判断，从上述代码的74-78行可以看到，从数据库读取数据之后，如果请求的缓存仍然为空，那么就缓存一个不存在的值，避免缓存穿透。\n2.2 回源数据分批请求数据库 如果缓存未命中，就需要从数据库中回源访问，Kratos的回源访问支持多线程并发访问，见上述代码38-62行。上述代码首先使用了github.com/go-kratos/kratos/pkg/sync/errgroup包， 定义了回源函数，然后将总的数据库请求分片，分批执行。\n这里errgroup包的作用是什么呢？errgroup实际上是一个并发工具，可以并发执行子任务，等待子任务返回，并提供每一个子任务的错误堆栈，执行出错返回的功能。其内部使用了channel存储要执行的任务，其核心对象如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49  // A Group is a collection of goroutines working on subtasks that are part of // the same overall task. // // A zero Group is valid and does not cancel on error. type Group struct { \terr error // 最终的错误信息 \twg sync.WaitGroup // 用于确保所有子任务结束执行 \terrOnce sync.Once  \tworkerOnce sync.Once \tch chan func(ctx context.Context) error // 存储待处理的任务 \tchs []func(ctx context.Context) error  \tctx context.Context \tcancel func() // 出错后的取消函数 }  ...  // Go方法增加子任务 func (g *Group) Go(f func(ctx context.Context) error) { \tg.wg.Add(1) \tif g.ch != nil { \tselect { \tcase g.ch \u0026lt;- f: \tdefault: \tg.chs = append(g.chs, f) \t} \treturn \t} \tgo g.do(f) }  // Wait方法等待所有子任务结束 func (g *Group) Wait() error { \tif g.ch != nil { \tfor _, f := range g.chs { \tg.ch \u0026lt;- f \t} \t} \tg.wg.Wait() \tif g.ch != nil { \tclose(g.ch) // let all receiver exit \t} \tif g.cancel != nil { \tg.cancel() \t} \treturn g.err }   2.3 异步添加缓存 如果缓存未命中，从数据库回源之后，还需要将数据加入到缓存中。但是当前请求已经获取了客户端需要的数据，因此这时候可以采用异步添加缓存的策略，当前请求直接返回给客户端。从2.1 部分开始前的代码83-85行可以看到，Kratos使用了github.com/go-kratos/kratos/pkg/sync/pipeline/fanout包来异步增加缓存。\nfanout包可以理解为一个用groutine实现的线程池，有goroutine数量、任务buffer大小两个核心参数，其内部使用了buffer类型的channel来存储任务，其处理任务的核心代码为：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40  // New new a fanout struct. func New(name string, opts ...Option) *Fanout { \tif name == \u0026#34;\u0026#34; { \tname = \u0026#34;anonymous\u0026#34; \t} \to := \u0026amp;options{ \tworker: 1, \tbuffer: 1024, \t} \tfor _, op := range opts { \top(o) \t} \tc := \u0026amp;Fanout{ \tch: make(chan item, o.buffer), \tname: name, \toptions: o, \t} \tc.ctx, c.cancel = context.WithCancel(context.Background()) \tc.waiter.Add(o.worker)  // 在这里启动worker \tfor i := 0; i \u0026lt; o.worker; i++ { \tgo c.proc() \t} \treturn c } ... func (c *Fanout) proc() { \tdefer c.waiter.Done() \tfor { \tselect {  // 循环处理channel中待处理的任务 \tcase t := \u0026lt;-c.ch: \twrapFunc(t.f)(t.ctx) \t_metricChanSize.Set(float64(len(c.ch)), c.name) \t_metricCount.Inc(c.name) \tcase \u0026lt;-c.ctx.Done(): \treturn \t} \t} }   2.4 监控缓存命中率 缓存监控的重点指标是缓存命中率，Kratos在也是在请求缓存之后，根据请求结果统计了如下数据：\n 请求缓存之后记录缓存命中数 请求缓存之后记录缓存未命中数  具体实现上，也是使用了封装的prometheus客户端代码提供监控入口：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  const _metricNamespace = \u0026#34;cache\u0026#34;  // be used in tool/kratos-gen-bts var ( \tMetricHits = metric.NewCounterVec(\u0026amp;metric.CounterVecOpts{ \tNamespace: _metricNamespace, \tSubsystem: \u0026#34;\u0026#34;, \tName: \u0026#34;hits_total\u0026#34;, \tHelp: \u0026#34;cache hits total.\u0026#34;, \tLabels: []string{\u0026#34;name\u0026#34;}, \t}) \tMetricMisses = metric.NewCounterVec(\u0026amp;metric.CounterVecOpts{ \tNamespace: _metricNamespace, \tSubsystem: \u0026#34;\u0026#34;, \tName: \u0026#34;misses_total\u0026#34;, \tHelp: \u0026#34;cache misses total.\u0026#34;, \tLabels: []string{\u0026#34;name\u0026#34;}, \t}) )   2.5 使用singleflight模式避免缓存失效引起的缓存雪崩 缓存数据本身是一个短时数据，超过一定的时间后，缓存可能会失效，也可能被业务系统主动驱逐。\u0026ldquo;缓存雪崩是指当缓存失效后引起系统性能急剧下降的情况。当缓存过期被清除后，业务系统需要重新生成缓存，因此需要再次访问存储系统，再次进行运算，这个处理步骤耗时几十毫秒甚至上百毫秒。而对于一个高并发的业务系统来说，几百毫秒内可能会接到几百上千个请求。由于旧的缓存已经被清除，新的缓存还未生成，并且处理这些请求的线程都不知道另外有一个线程正在生成缓存，因此所有的请求都会去重新生成缓存，都会去访问存储系统，从而对存储系统造成巨大的性能压力。这些压力又会拖慢整个系统，严重的会造成数据库宕机，从而形成一系列连锁反应，造成整个系统崩溃。\u0026quot;[1]\n针对这个问题，Kratos使用了singleflight模式（https://github.com/golang/sync/blob/master/singleflight/singleflight.go），如果一个key失效了，同一时间只允许一个线程执行缓存更新操作。这个方法限制了缓存更新的并发度，有助于解决缓存雪崩问题。\n要使用kratos tool genbts 生成singleflight模式的代码，需要增加如下-singleflight=true配置：\n1 2  // bts: -sync=true -nullcache=\u0026amp;Demo{ID:-1} -check_null_code=$.ID==-1 -singleflight=true Demo(c context.Context, key int64) (*Demo, error)   生成代码中增加了一个全局变量cacheSingleFlights限制回源请求的并发度：\n1  var cacheSingleFlights = [1]*singleflight.Group{{}}   然后在具体的回源代码中：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38  // Demo get data from cache if miss will call source method, then add to cache. func (d *dao) Demo(c context.Context, key int64) (res *Demo, err error) { \taddCache := true \tres, err = d.CacheDemo(c, key) \tif err != nil { \taddCache = false \terr = nil \t} \tdefer func() { \tif res.ID == -1 { \tres = nil \t} \t}() \tif res != nil { \tcache.MetricHits.Inc(\u0026#34;bts:Demo\u0026#34;) \treturn \t} \tvar rr interface{} \tsf := d.cacheSFDemo(key) \trr, err, _ = cacheSingleFlights[0].Do(sf, func() (r interface{}, e error) { \tcache.MetricMisses.Inc(\u0026#34;bts:Demo\u0026#34;) \tr, e = d.RawDemo(c, key) \treturn \t}) \tres = rr.(*Demo) \tif err != nil { \treturn \t} \tmiss := res \tif miss == nil { \tmiss = \u0026amp;Demo{ID: -1} \t} \tif !addCache { \treturn \t} \td.AddCacheDemo(c, key, miss) \treturn }   从18到28行的调用可以看到，Kratos使用全局变量cacheSingleFlights限制了数据库回源请求RawDemo()的并发度，如果看一下singleflight的实现，可以看到其内部使用了map存储要执行的函数，确保在同一时间，同一个函数只被执行一次。\nsingleflight模式只限制了，在缓存失效时，一个进程内只有一个请求到达数据库。在当前的微服务架构下，如果一个服务有上百个副本在运行，那么也有可能造成数据库压力增加，这种情况下可以采用分布式锁或者后台更新缓存的策略。\n3 总结 本文从源码的角度讨论了Kratos生成的缓存回源代码的一些功能。\n引用 [1] 高性能缓存架构 https://time.geekbang.org/column/article/8640\n","permalink":"https://tianyuxue.github.io/posts/kratos-src-cache/","summary":"\u003cblockquote\u003e\n\u003cp\u003e本文的讨论基于Kratos v1.0.x版本\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eKratos是bilibili开源的一套Go微服务框架，包含大量微服务相关框架及工具，本文主要从源码角度分析一下Kratos中与缓存相关的代码，在分析的过程中，我会从Kratos提供的不同的功能点来结合自己的一些理解进行阐述（这篇文章没有复杂的原理，只有从工程角度的一些最佳实践)。\u003c/p\u003e","title":"Kratos源码分析 - 缓存部分"},{"content":" 本文的讨论基于Kratos v1.0.x版本\n Kratos是bilibili开源的一套Go微服务框架，包含大量微服务相关框架及工具，本文主要从源码角度分析一下Kratos中与MySQL相关的代码，在分析的过程中，我会从Kratos提供的不同的功能点来结合自己的一些理解进行阐述（这篇文章没有复杂的原理，只有从工程角度的一些最佳实践)。\n1 核心对象的封装 Kratos的数据层代码主要是对Golang SDK的二次封装。在GolangSDK中，database/sql包提供了对SQL的支持，具体而言，这个包提供了如下的抽象：\n DB 抽象表示数据库本身，也可以将其理解为数据库连接池 Conn 抽象表示单独一个数据库连接 Tx 抽象表示一次数据库事务操作 Stmt 抽象表示一个Prepared Statement Row/Rows 抽象表示一次数据库交互后的结果  database/sql包提供的这些抽象接口是直观的，易用的，足够应付简单的应用场景。Kratos对上面这几个对象再次进行了封装，提供了实际开发中经常用到的如下功能：\n MySQL读写分离 链路追踪 统计信息 慢查询日志记录 融断保护  下面我从代码的角度分析下Kratos是如何实现上述功能的。\n2 功能点的实现 2.1 MySQL读写分离 Kratos从DAO层的代码层面实现了对MySQL读写分离的支持，并未使用数据库中间件。首先看下Kratos需要用户提供的MySQL集群配置信息：\n1 2 3 4 5 6 7 8 9 10 11 12  pkg/database/sql/mysql.go type Config struct {  DSN string // write data source name.  ReadDSN []string // read data source name  Active int // pool  Idle int // pool  IdleTimeout time.Duration // connect max life time.  QueryTimeout time.Duration // query sql timeout  ExecTimeout time.Duration // execute sql timeout  TranTimeout time.Duration // transaction sql timeout  Breaker *breaker.Config // breaker }   可以看出，DSN和ReadDSN分别存储了MySQL主节点地址和从节点地址，从节点地址有多个。Kratos会根据上述配置，生成如下的连接池对象：\n1 2 3 4 5 6  type DB struct { write *conn //主节点连接池，conn定义见下文 read []*conn //从节点连接池 idx int64 // 用于选取从节点的id master *DB //MySQL的主节点 }   DB对象使用master字段冗余存储主节点的信息，用来支持一些特定业务场景下，必须查询主库的操作。write/read字段分别表示数据库具体连接池，从conn类型的定义可以看到，其内部封装了Golang SDK中的 sql.DB对象：\n1 2 3 4 5 6 7  // conn database connection type conn struct {  *sql.DB // 对Golang SDK连接池的封装，用来支持MySQL读写分离  breaker breaker.Breaker  conf *Config  addr string }   这样通过把Golang SDK中的sql.DB嵌入到conn对象中，再把多个conn对象封装到DB对象中，就使Kratos的DB对象支持了对MySQL集群的多个实例的读写。下面是Kratos中查询从库的方法：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  // Query executes a query that returns rows, typically a SELECT. The args are // for any placeholder parameters in the query. func (db *DB) Query(c context.Context, query string, args ...interface{}) (rows *Rows, err error) {  // 获取要读取哪一个从库 \tidx := db.readIndex() \tfor i := range db.read { \t// 依次尝试每一个从库, 只要一个成功了就返回 \tif rows, err = db.read[(idx+i)%len(db.read)].query(c, query, args...); !ecode.EqualError(ecode.ServiceUnavailable, err) { \treturn \t} \t} \t// 从库失败了的话就查询主库 \treturn db.write.query(c, query, args...) }  ...  // 简单的使用轮询策略选择要读取的从库 func (db *DB) readIndex() int { \tif len(db.read) == 0 { \treturn 0 \t} \tv := atomic.AddInt64(\u0026amp;db.idx, 1) \treturn int(v) % len(db.read) }   从readIndex()方法中可以看到，Kratos在查询从库时候使用了简单轮寻的方法，每次查询前使用cas方式将内部变量idx自增，然后通过取mod的方式确定要查询哪一个从库。Query()方法中循环尝试读取每一个从库，只有读取成功了一次后才返回，这样避免了个别从库故障导致的读取失败。\n除了读操作之外，对于写入的操作，Kratos同样对Golang SDK中sql.DB的如下方法进行了封装：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  // 启动MySQL事务 func (db *DB) Begin(c context.Context) (tx *Tx, err error) { \treturn db.write.begin(c) }  // 执行无返回结果的SQL语句 func (db *DB) Exec(c context.Context, query string, args ...interface{}) (res sql.Result, err error) { \treturn db.write.exec(c, query, args...) }  // 创建Prepared Statement，如果出错会返回错误信息 func (db *DB) Prepare(query string) (*Stmt, error) { \treturn db.write.prepare(query) }  // 创建Prepared Statement，如果出错会后台重试 func (db *DB) Prepared(query string) (stmt *Stmt) { \treturn db.write.prepared(query) }   通过上述几个方法的封装，Kratos直接使用主库的数据库连接池进行插入删除等操作。这样Kratos在DAO的代码层面实现对Golang原生database/sql包的封装。\n再看一下prepare statement的创建, Kratos的提供了Prepared()方法，如果创建prepare statement错误，那么启动一个goroutine不断重试，直到创建成功了，就用cas方法把prepare statement存储在Kratos封装的Stmt对象中， 个人感觉这样不够优雅，不知道b站内部是怎么用这个方法的：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45  // Stmt prepared stmt. type Stmt struct { \tdb *conn \ttx bool \tquery string \tstmt atomic.Value // 存储创建好的prepare statement \tt trace.Trace }  ...  func (db *conn) prepare(query string) (*Stmt, error) { \tdefer slowLog(fmt.Sprintf(\u0026#34;Prepare query(%s)\u0026#34;, query), time.Now()) \tstmt, err := db.Prepare(query) \tif err != nil { \terr = errors.Wrapf(err, \u0026#34;prepare %s\u0026#34;, query) \treturn nil, err \t} \tst := \u0026amp;Stmt{query: query, db: db} \tst.stmt.Store(stmt) \treturn st, nil }  func (db *conn) prepared(query string) (stmt *Stmt) { \tdefer slowLog(fmt.Sprintf(\u0026#34;Prepared query(%s)\u0026#34;, query), time.Now()) \tstmt = \u0026amp;Stmt{query: query, db: db} \ts, err := db.Prepare(query) \tif err == nil { \tstmt.stmt.Store(s) \treturn \t} \t// 如果执行创建prepare出错了，这里后台执行不断重试，直到成功为止 \tgo func() { \tfor { \ts, err := db.Prepare(query) \tif err != nil { \ttime.Sleep(time.Second) \tcontinue \t} \tstmt.stmt.Store(s) \treturn \t} \t}() \treturn }   除了MySQL读写分离，Kratos对其他方法的封装主要是为了提供慢查询日志，trace日志，监控信息和熔断保护这四个功能。\n2.2 慢查询日志 Kratos在每个与数据库交互方法中记录了慢查询日志，结合关键字defer，其实现方法非常简单：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  ... func (db *conn) Query(c context.Context) (tx *Tx, err error) { \t// 获取当前时间，通过defer来确定结束时间  now := time.Now() \tdefer slowLog(\u0026#34;Begin\u0026#34;, now)  ...  // 时间超过阈值，就打印一条警告记录 func slowLog(statement string, now time.Time) { \tdu := time.Since(now) \tif du \u0026gt; _slowLogDuration { \tlog.Warn(\u0026#34;%s slow log statement: %s time: %v\u0026#34;, _family, statement, du) \t} }   与数据库交互的每个方法中，Kratos都加入了上述代码片段记录慢查询的警告日志。\n2.3 监控信息 在数据库链接层面，Kratos封装了prometheus客户端代码，提供了4个主要的监控信息：\n 请求处理时长 错误请求数 数据库连接总数 当前数据库连接数  具体的代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39  pkg/database/sql/metrics.go  package sql  import \u0026#34;github.com/go-kratos/kratos/pkg/stat/metric\u0026#34;  const namespace = \u0026#34;mysql_client\u0026#34;  var ( \t_metricReqDur = metric.NewHistogramVec(\u0026amp;metric.HistogramVecOpts{ \tNamespace: namespace, \tSubsystem: \u0026#34;requests\u0026#34;, \tName: \u0026#34;duration_ms\u0026#34;, \tHelp: \u0026#34;mysql client requests duration(ms).\u0026#34;, \tLabels: []string{\u0026#34;name\u0026#34;, \u0026#34;addr\u0026#34;, \u0026#34;command\u0026#34;}, \tBuckets: []float64{5, 10, 25, 50, 100, 250, 500, 1000, 2500}, \t}) \t_metricReqErr = metric.NewCounterVec(\u0026amp;metric.CounterVecOpts{ \tNamespace: namespace, \tSubsystem: \u0026#34;requests\u0026#34;, \tName: \u0026#34;error_total\u0026#34;, \tHelp: \u0026#34;mysql client requests error count.\u0026#34;, \tLabels: []string{\u0026#34;name\u0026#34;, \u0026#34;addr\u0026#34;, \u0026#34;command\u0026#34;, \u0026#34;error\u0026#34;}, \t}) \t_metricConnTotal = metric.NewCounterVec(\u0026amp;metric.CounterVecOpts{ \tNamespace: namespace, \tSubsystem: \u0026#34;connections\u0026#34;, \tName: \u0026#34;total\u0026#34;, \tHelp: \u0026#34;mysql client connections total count.\u0026#34;, \tLabels: []string{\u0026#34;name\u0026#34;, \u0026#34;addr\u0026#34;, \u0026#34;state\u0026#34;}, \t}) \t_metricConnCurrent = metric.NewGaugeVec(\u0026amp;metric.GaugeVecOpts{ \tNamespace: namespace, \tSubsystem: \u0026#34;connections\u0026#34;, \tName: \u0026#34;current\u0026#34;, \tHelp: \u0026#34;mysql client connections current.\u0026#34;, \tLabels: []string{\u0026#34;name\u0026#34;, \u0026#34;addr\u0026#34;, \u0026#34;state\u0026#34;}, \t}) )   Kratos已经把上面监控数据嵌入在封装好的数据库交互的方法中，例如数据库读写发生错误后会调用_metricReqErr.Inc(), 读写完成后会调用_metricReqDur.Observe()。\n2.4 断路器 Kratos的DB对象内置了断路器，存储在DB对象的breaker字段中，断路器的接口很简单，主要提供了如下三个方法：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40  // Breaker 定义了断路器接口 type Breaker interface { \tAllow() error \tMarkSuccess() \tMarkFailed() }  ... //在连接发出请求前判断熔断器状态 if err = conn.breaker.Allow(); err != nil {  return }  //连接执行成功或失败将结果告知breaker if(respErr != nil){  conn.breaker.MarkFailed() }else{  conn.breaker.MarkSuccess() }  Kratos在与数据库交互前会检查断路器状态，执行完SQL语句后更新断路器状态，例如在exec()方法中：  func (db *conn) exec(c context.Context, query string, args ...interface{}) (res sql.Result, err error) {  ...  // 执行方法前确认断路器状态 \tif err = db.breaker.Allow(); err != nil { \t_metricReqErr.Inc(db.addr, db.addr, \u0026#34;exec\u0026#34;, \u0026#34;breaker\u0026#34;) \treturn \t} \t_, c, cancel := db.conf.ExecTimeout.Shrink(c) \tres, err = db.ExecContext(c, query, args...) \tcancel()  // 方法执行完毕后更新断路器状态 \tdb.onBreaker(\u0026amp;err) \t_metricReqDur.Observe(int64(time.Since(now)/time.Millisecond), db.addr, db.addr, \u0026#34;exec\u0026#34;) \tif err != nil { \terr = errors.Wrapf(err, \u0026#34;exec:%s, args:%+v\u0026#34;, query, args) \t} \treturn }   2.5 trace信息 Kratos通过context来传递trace信息，见如下代码：\n1 2 3 4 5  if t, ok := trace.FromContext(c); ok {  t = t.Fork(_family, \u0026#34;exec\u0026#34;) \tt.SetTag(trace.String(trace.TagAddress, db.addr), trace.String(trace.TagComment, query)) \tdefer t.Finish(\u0026amp;amp;err) }   在从context获取了trace的记录单元后，同样使用了defer关键字记录了日志的终止信息。上述代码片段在每一个数据库交互方法中都存在，这样就实现了在读写数据库层面的trace信息记录。\n3 总结 本文从源码层面讨论了Kratos框架对读写MySQL提供的一些工程上的最佳实践。\n","permalink":"https://tianyuxue.github.io/posts/kratos-src-mysql/","summary":"\u003cblockquote\u003e\n\u003cp\u003e本文的讨论基于Kratos v1.0.x版本\u003c/p\u003e\n\u003c/blockquote\u003e\n\u003cp\u003eKratos是bilibili开源的一套Go微服务框架，包含大量微服务相关框架及工具，本文主要从源码角度分析一下Kratos中与MySQL相关的代码，在分析的过程中，我会从Kratos提供的不同的功能点来结合自己的一些理解进行阐述（这篇文章没有复杂的原理，只有从工程角度的一些最佳实践)。\u003c/p\u003e","title":"Kratos 源码分析 - MySQL部分"},{"content":" 本文介绍了Golang中GC的执行过程，然后用一个例子，结合golang提供的GC日志和pprof工具，介绍GC调优的基本方法\n本文的讨论基于golang 1.15.4版本\n 1 Golang采用的GC方案 Golang采用了并发标记-清除的GC方法，非分代，没有内存整理和移动，这与JVM有很大的不同。对于整个GC过程，源码runtime/mgc.go中给出了较为详细的描述，这里再做一个简要的梳理。整个GC分为以下4个阶段：\n1.sweep termination\n这个阶段发生在真正GC之前，用来清除上次GC后未被回收的内存，通常这个阶段不会发生，只有在执行了force gc的时候才会触发这个阶段，比如手动调用runtime.GC()函数。\n2.mark\nmark阶段分为如下几步：\n  将变量gcphase从_GCoff设置为 _GCmark、开启写屏障功能、启动GC Assists。这个阶段会STW(Stop The World)，用户代码会暂停，直到所有P启动写屏障功能为止(如果对P的概念不理解，可以查看另一篇文章了解golang调度的原理)。\n  写屏障启动之后会结束STW状态，用户代码可以正常执行，调度器启动GC Goroutine执行真正的标记任务，GC Assists开始接管GC过程中的内存分配，在这个过程中：\n  写屏障会将GC过程中修改过的对象标记为灰色，GC过程中新分配的对象则直接标记为黑色，写屏障的作用是为了维持三色不变性，保证三色标记GC算法正常工作（三色标记算法过程后文介绍）\n  GC Assist用来调节GC过程中的内存分配速度，直观理解，就是GC过程中，用户Goroutine分配的内存越多，其分配速度越慢，甚至会被调度器执行抢占式调度。\n    GC Goroutine 会扫描所有栈，按照三色标记算法给扫描到的变量标记颜色, 扫描栈的时候，会暂停对应的goroutine, 扫描完成后再恢复gorouine的执行。\n  三色标记算法的原理如下：\n  初始所有变量为白色\n  首先将全局变量、被栈引用的堆内对象标记为灰色\n  随机选择一个灰色的对象，将其标记为黑色\n 接着扫描该对象的所有可达对象，将可达对象也标记为灰色    重复上述过程，直到没有灰色的对象为止\n  这时候白色对象就是可以被回收的。可以看出在整个算法过程中，灰色表示待扫描的对象，黑色代表扫描完毕不可以回收的对象，白色代表可回收的对象，这个不变的特性就称为三色不变性。\n      3.mark termination\n在GC Goroutine扫描完所有的栈之后进入mark termination阶段，这个阶段同样会STW(Stop The World), 设置gcphase变量为_GCmarktermination, 然后执行一些资源清理的工作：\n 停止GC Goroutine 禁用GC Assists  4.sweep\n标记结束之后进入sweep阶段，设置gcphace为 _GCoff, 禁用写屏障, 在这之后会Start The World， 启动执行用户代码，这时候意味着并发标记已经结束了，剩下的就是内存回收的工作了。\n 从这个阶段开始，新的内存分配请求会复用被标记为可回收的内存，这意味着内存的回收是惰性的，不是立刻回收。 基于cpu使用情况，调度器可能启动额外的goroutine来执行内存回收  当新分配的内存达到GOGC设定的值后，再次触发GC, 重复上述步骤。\n GOGC用于调整GC频率，GOGC的默认值是100, 意味着下一次GC的触发时机是： 新分配的内存 = 当前GC结束后的剩余内存 × 100%， 例如当前GC结束后剩余4MB内存，当堆内存达到8MB时候，会再次触发GC  GC过程示意图\n整个GC的过程可以见上图。这里再罗嗦一下，Golang采用无内存复制/移动的GC算法，很大的原因是为了兼容谷歌内部的大量C和C++代码，如果GC导致了堆对象的地址变化，那么对于调用C和C++代码而言非常困难。而由于协程的使用，启动写屏障、调度器启动GC Goroutine等操作实际是不涉及内核线程的上下文切换的，因此STW速度很快，这也是并发标记清除算法名称的由来，因此我们看到了Golang这种跟JVM完全不同的内存回收方案。\n2 实践GC调优 程序代码的执行必然伴随着内存的分配、修改和释放，GC将程序员从手动内存管理的繁琐工作中解放了出来，很大程度上提高了开发效率。就像任何事情一样，GC也不是免费的，GC的代价就在于消耗了CPU来执行了业务无关代码，从而造成用户代码执行的延迟。从这一点看GC调优与优化内存使用是密切相关的，造成GC过度延迟的根本原因就在于不恰当的内存分配和使用。\nGC调优的目的很简单：节约堆内存，降低GC造成的CPU消耗，避免因为GC而导致用户代码执行延迟，尤其是在某些延迟敏感的特定场景。衡量GC损耗的关键指标有三个：GC过程中的cpu使用率，STW时间和STW频率，这三个指标通常是互相关联的，总体上来说，GC的调优就是需要尽量减少内存分配和释放，尽量复用已经分配的内存。\n下面通过一个例子来分析GC调优的一些方法，这个例子中首先创建了长度为1000的256位随机字符串数组，然后在每一个web请求中随机生成一个字符串，然后再到字符串数组中查找，这个过程是对查找用户缓存的一个简单模拟，具体代码功能可以参考注释：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51  package main  import ( \t\u0026#34;io\u0026#34; \t\u0026#34;math/rand\u0026#34; \t\u0026#34;net/http\u0026#34;  \t// 用于启动pprof的web接口 \t_ \u0026#34;net/http/pprof\u0026#34;  \t\u0026#34;strings\u0026#34; )  // ids 模拟含有1000个用户id的缓存 var ids = make([]string, 1000)  func main() { \t// 初始化缓存 \tfor i := 0; i != 1000; i++ { \ts := getRandString(256) \tids = append(ids, s) \t}  \thttp.HandleFunc(\u0026#34;/slowgc\u0026#34;, slowGC) \thttp.ListenAndServe(\u0026#34;:8080\u0026#34;, nil) }  // slowGC 模拟由于内存分配导致的GC func slowGC(w http.ResponseWriter, r *http.Request) { \tcurrentUser := getRandString(256) \tfor _, id := range ids { \t// 这里调用了strings.ToLower函数，这个函数会导致字符串的复制 \tif strings.Contains(strings.ToLower(currentUser), strings.ToLower(id)) { \t// if strings.Contains(id, currentUser) { \tio.WriteString(w, \u0026#34;hit\u0026#34;) \t} \t} \tio.WriteString(w, \u0026#34;not found\u0026#34;) }  const letters = \u0026#34;abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ\u0026#34;  // getRandString 生成指定位数的字符串 func getRandString(length int) string { \trnd := make([]byte, length) \tfor i := range rnd { \trnd[i] = letters[rand.Intn(len(letters))] \t} \ts := string(rnd) \treturn s }   2.1 分析GC问题的瓶颈 要观察GC信息主要有以下三种方式\n 使用GODEBUG=gctrace=1参数启动程序观察GC日志 go tool pprof工具可以用来详细分析内存分配，找出程序哪里分配了不合理的内存造成了GC压力 go tool trace工具可以列出整个代码执行过程中的详细信息。  下面我们通过上述的例子，打开GODEBUG=gctrace=1来分析一下GC信息。首先我们执行如下命令启动程序：\n1 2  go build main.go GODEBUG=gctrace=1 ./main   接着使用ab工具对接口进行压力测试：\n1 2 3  # -c 表示同时发送100个请求 # -n 表示请求总量一共10000个 ab -c 100 -n 10000 http://localhost:8080/slowgc   ab工具可以得到类似的结果：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54  ab -c 100 -n 10000 http://localhost:8080/slowgc This is ApacheBench, Version 2.3 \u0026lt;$Revision: 1843412 $\u0026gt; Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/ Licensed to The Apache Software Foundation, http://www.apache.org/  Benchmarking localhost (be patient) Completed 1000 requests Completed 2000 requests Completed 3000 requests Completed 4000 requests Completed 5000 requests Completed 6000 requests Completed 7000 requests Completed 8000 requests Completed 9000 requests Completed 10000 requests Finished 10000 requests   Server Software: Server Hostname: localhost Server Port: 8080  Document Path: /slowgc Document Length: 3009 bytes  Concurrency Level: 100 Time taken for tests: 23.753 seconds Complete requests: 10000 Failed requests: 0 Total transferred: 31060000 bytes HTML transferred: 30090000 bytes Requests per second: 421.00 [#/sec] (mean) Time per request: 237.529 [ms] (mean) Time per request: 2.375 [ms] (mean, across all concurrent requests) Transfer rate: 1276.98 [Kbytes/sec] received  Connection Times (ms)  min mean[+/-sd] median max Connect: 0 0 0.3 0 5 Processing: 6 237 136.6 210 1217 Waiting: 6 230 136.2 204 1217 Total: 6 237 136.6 210 1217  Percentage of the requests served within a certain time (ms)  50% 210  66% 263  75% 301  80% 331  90% 412  95% 489  98% 598  99% 704  100% 1217 (longest request)   可以看出上面代码的简单逻辑，每秒钟处理的请求数量只有421个，按道理来说简单的字符串查找不应该这么慢，那么问题出在哪里呢，接着看下刚才过程中的gctrace信息：\n... gc 2619 @25.802s 9%: 0.060+0.61+0.019 ms clock, 0.24+0.73/0.49/0+0.079 ms cpu, 4-\u0026gt;4-\u0026gt;1 MB, 5 MB goal, 4 P gc 2620 @25.810s 9%: 0.085+0.68+0.022 ms clock, 0.34+0.80/0.57/0+0.088 ms cpu, 4-\u0026gt;4-\u0026gt;0 MB, 5 MB goal, 4 P gc 2621 @25.818s 9%: 0.057+0.42+0.019 ms clock, 0.23+0.63/0.30/0+0.076 ms cpu, 4-\u0026gt;4-\u0026gt;0 MB, 5 MB goal, 4 P gc 2622 @25.826s 9%: 0.76+1.7+0.019 ms clock, 3.0+1.9/0.40/0+0.078 ms cpu, 4-\u0026gt;4-\u0026gt;1 MB, 5 MB goal, 4 P 观察压测结束后的gc日志，可以看出10000个请求一共触发了2622次GC，其中GC Groutine一共使用了将近百分之十的CPU，在这样一个简单的业务逻辑下，GC触发的频率明显过高，并且占用的CPU时间也过高（关于GC trace信息的阅读可以参考文末附录），这是不合理的，GC的行为不符合预期的时候，我们首先应该从内存是否合理分配来入手分析，接下来我们可以使用go tool pprof工具来查看一下上述代码的内存使用情况：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39  go tool pprof http://localhost:8080/debug/pprof/allocs Fetching profile over HTTP from http://localhost:8080/debug/pprof/allocs Saved profile in /root/pprof/pprof.go-gc-tutorial.alloc_objects.alloc_space.inuse_objects.inuse_space.001.pb.gz File: go-gc-tutorial Type: alloc_space Time: Jan 2, 2021 at 9:39pm (CST) Entering interactive mode (type \u0026#34;help\u0026#34; for commands, \u0026#34;o\u0026#34; for options) (pprof) top 6 -cum Showing nodes accounting for 0, 0% of 7.26GB total Dropped 58 nodes (cum \u0026lt;= 0.04GB) Showing top 6 nodes out of 8  flat flat% sum% cum cum%  0 0% 0% 7.25GB 99.91% net/http.(*conn).serve  0 0% 0% 7.16GB 98.68% main.slowGC  0 0% 0% 7.16GB 98.68% net/http.(*ServeMux).ServeHTTP  0 0% 0% 7.16GB 98.68% net/http.HandlerFunc.ServeHTTP  0 0% 0% 7.16GB 98.68% net/http.serverHandler.ServeHTTP  0 0% 0% 7.16GB 98.61% strings.(*Builder).Grow (inline) (pprof) (pprof) list slowGC Total: 7.26GB ROUTINE ======================== main.slowGC in /data/codes/go-gc/main1.go  0 7.16GB (flat, cum) 98.68% of Total  . . 25:\thttp.ListenAndServe(\u0026#34;:8080\u0026#34;, nil)  . . 26:}  . . 27:  . . 28:// slowGC 模拟由于内存分配导致的GC  . . 29:func slowGC(w http.ResponseWriter, r *http.Request) {  . 4.50MB 30:\tcurrentUser := getRandString(256)  . . 31:\tfor _, id := range ids {  . . 32:\t// 这里调用了strings.ToLower函数，这个函数会导致字符串的复制  . 7.16GB 33:\tif strings.Contains(strings.ToLower(currentUser), strings.ToLower(id)) {  . . 34:\t// if strings.Contains(id, currentUser) {  . 512.02kB 35:\tio.WriteString(w, \u0026#34;hit\u0026#34;)  . . 36:\t}  . . 37:\t}  . . 38:\tio.WriteString(w, \u0026#34;not found\u0026#34;)  . . 39:}  . . 40:   首先使用命令\ngo tool pprof http://localhost:8080/debug/pprof/allocs 进入pprof工具的交互模式，然后输人top 5 -cum查看分配内存最多的5个函数，从输出结果我们可以看出，slowGC函数分配了7GB左右的内存，这有一些奇怪，然后我们可以执行list slowGC命令，可以看出在第33行调用的操作字符串的方法分配内存最多，至此原因大概明白了，golang中string类型是不可变的，每次调用strings.ToLower()方法时候都会申请内存分配一个新的字符串，最后就造成的每次循环中都会申请一块新内存，从而造成GC压力（调用ToLower()方法只是为了举例说明GC问题，并无实际的意义）。我们可以针对这个问题做一下简单的修改，将第33行的ToLower()函数移动到循环之外：\npackage main import ( \u0026#34;io\u0026#34; \u0026#34;math/rand\u0026#34; \u0026#34;net/http\u0026#34; // 用于启动pprof的web接口 _ \u0026#34;net/http/pprof\u0026#34; \u0026#34;strings\u0026#34; ) // ids 模拟含有1000个用户id的缓存 var ids = make([]string, 1000) func main() { // 初始化缓存 for i := 0; i != 1000; i++ { s := getRandString(256) s = strings.ToLower(s) ids = append(ids, s) } http.HandleFunc(\u0026#34;/slowgc\u0026#34;, slowGC) http.ListenAndServe(\u0026#34;:8080\u0026#34;, nil) } // slowGC 模拟由于内存分配导致的GC func slowGC(w http.ResponseWriter, r *http.Request) { currentUser := getRandString(256) // 将ToLower()的调用移动到循环之外 currentUser = strings.ToLower(currentUser) for _, id := range ids { if strings.Contains(id, currentUser) { io.WriteString(w, \u0026#34;hit\u0026#34;) } } io.WriteString(w, \u0026#34;not found\u0026#34;) } const letters = \u0026#34;abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ\u0026#34; // getRandString 生成指定位数的字符串 func getRandString(length int) string { rnd := make([]byte, length) for i := range rnd { rnd[i] = letters[rand.Intn(len(letters))] } s := string(rnd) return s } 再次执行上述压测命令，可以看到压测结果为：\nab -c 100 -n 10000 http://localhost:8080/slowgc This is ApacheBench, Version 2.3 \u0026lt;$Revision: 1843412 $\u0026gt; Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/ Licensed to The Apache Software Foundation, http://www.apache.org/ Benchmarking localhost (be patient) Completed 1000 requests Completed 2000 requests Completed 3000 requests Completed 4000 requests Completed 5000 requests Completed 6000 requests Completed 7000 requests Completed 8000 requests Completed 9000 requests Completed 10000 requests Finished 10000 requests Server Software: Server Hostname: localhost Server Port: 8080 Document Path: /slowgc Document Length: 9 bytes Concurrency Level: 100 Time taken for tests: 0.880 seconds Complete requests: 10000 Failed requests: 0 Total transferred: 1250000 bytes HTML transferred: 90000 bytes Requests per second: 11369.89 [#/sec] (mean) Time per request: 8.795 [ms] (mean) Time per request: 0.088 [ms] (mean, across all concurrent requests) Transfer rate: 1387.93 [Kbytes/sec] received Connection Times (ms) min mean[+/-sd] median max Connect: 0 4 0.8 3 10 Processing: 1 5 1.8 5 19 Waiting: 1 4 1.6 4 17 Total: 4 9 1.8 8 23 WARNING: The median and mean for the initial connection time are not within a normal deviation These results are probably not that reliable. Percentage of the requests served within a certain time (ms) 50% 8 66% 9 75% 9 80% 10 90% 11 95% 12 98% 13 99% 16 100% 23 (longest request) 从ab命令执行结果来看，处理速度有了极大的改进，每秒处理的请求数量达到了11369，而查看gctrace日志，也可以看到整个过程中只触发了10几次GC：\n... gc 10 @5.149s 0%: 0.097+0.84+0.007 ms clock, 0.38+1.4/0.001/0+0.028 ms cpu, 4-\u0026gt;4-\u0026gt;1 MB, 5 MB goal, 4 P gc 11 @5.208s 0%: 0.037+0.79+0.004 ms clock, 0.14+0.65/0.56/0.25+0.016 ms cpu, 4-\u0026gt;4-\u0026gt;1 MB, 5 MB goal, 4 P gc 12 @5.277s 0%: 0.039+0.71+0.003 ms clock, 0.15+0.71/0.55/0+0.014 ms cpu, 4-\u0026gt;4-\u0026gt;1 MB, 5 MB goal, 4 P gc 13 @5.346s 0%: 0.023+1.0+0.013 ms clock, 0.094+0.78/0.66/0+0.055 ms cpu, 4-\u0026gt;4-\u0026gt;1 MB, 5 MB goal, 4 P 小结一下，这部分使用了gctrace日志和pprof工具发现了代码中内存分配的缺陷，通过修改代码解决了问题。\n2.2 调节GOGC参数 上述内存造成的问题也可通过调整GOGC参数来给予临时解决，为什么说是临时解决呢？因为通常修改GOGC参数，虽然减少了GC的触发频率，也可能会带来更长单次GC时间。要从根本上解决GC问题，还是要从代码，或者业务逻辑入手进行优化。下面我们再看下GOGC参数如何影响GC操作。我们用下面的命令设置GOGC的值为500， 意味着堆内存增长5倍，下一次GC才会触发，重新执行2.1中有问题的代码：\nGOGC=500 GODEBUG=gctrace=1 ./main 同样执行ab命令进行压测后，得到如下结果：\nab -c 100 -n 10000 http://localhost:8080/slowgc This is ApacheBench, Version 2.3 \u0026lt;$Revision: 1843412 $\u0026gt; Copyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/ Licensed to The Apache Software Foundation, http://www.apache.org/ Benchmarking localhost (be patient) Completed 1000 requests Completed 2000 requests Completed 3000 requests Completed 4000 requests Completed 5000 requests Completed 6000 requests Completed 7000 requests Completed 8000 requests Completed 9000 requests Completed 10000 requests Finished 10000 requests Server Software: Server Hostname: localhost Server Port: 8080 Document Path: /slowgc Document Length: 3009 bytes Concurrency Level: 100 Time taken for tests: 18.846 seconds Complete requests: 10000 Failed requests: 0 Total transferred: 31060000 bytes HTML transferred: 30090000 bytes Requests per second: 530.62 [#/sec] (mean) Time per request: 188.459 [ms] (mean) Time per request: 1.885 [ms] (mean, across all concurrent requests) Transfer rate: 1609.48 [Kbytes/sec] received Connection Times (ms) min mean[+/-sd] median max Connect: 0 0 0.3 0 4 Processing: 6 187 136.9 173 1171 Waiting: 5 184 135.5 170 1171 Total: 6 187 136.9 173 1171 Percentage of the requests served within a certain time (ms) 50% 173 66% 226 75% 256 80% 283 90% 362 95% 437 98% 545 99% 641 100% 1171 (longest request) 从ab命令结果可以看出，每秒的请求较之前的400多次变为了500多次，性能略有提升，而gc日志也可以看出，由于修改了GC触发的频率，实际触发的GC次数为394次，比之前的2000多次也是明显减少，整个GC过程的CPU使用率也维持在1%。通过这个例子可以看出，根据实际情况调整GC触发频率对于GC效率是会有较大提升的，但是具体如何设置GOGC的值就是一个开放问题了，需要在不同的场景下不断的测试，最终得到符合当前场景的参数值。\n... gc 391 @21.304s 1%: 0.063+0.58+0.015 ms clock, 0.25+0.81/0.53/0+0.061 ms cpu, 20-\u0026gt;20-\u0026gt;1 MB, 21 MB goal, 4 P gc 392 @21.350s 1%: 0.071+0.38+0.017 ms clock, 0.28+0.76/0.32/0+0.069 ms cpu, 20-\u0026gt;20-\u0026gt;1 MB, 21 MB goal, 4 P gc 393 @21.395s 1%: 0.059+0.36+0.015 ms clock, 0.23+0.57/0.29/0+0.061 ms cpu, 20-\u0026gt;20-\u0026gt;0 MB, 21 MB goal, 4 P gc 394 @21.439s 1%: 0.066+0.41+0.018 ms clock, 0.26+0.50/0.36/0+0.075 ms cpu, 20-\u0026gt;20-\u0026gt;0 MB, 21 MB goal, 4 P 2.3 GC调优的其他方法 除了上述的GC调优方法之外，golang编译器提供了逃逸分析的方法，具体而言就是编译器如果可以判断出一个变量创建后只存活在当前栈帧中，那么在当前栈被销毁时候，变量也可以直接销毁，这样就不再需要执行GC去做这部分工作。实际中可以使用go build -gcflags=-m来打开逃逸分析的提示。\n除了逃逸分析之外，另一种常见的控制内存分配的方法是将常用的内存对象池化，sync.Pool就提供了池化对象的支持，除此之外，很多三方库也可以使用，比如https://github.com/valyala/bytebufferpool。\n3 总结 本文首先介绍了Golang中GC的执行过程，然后用一个例子，结合golang提供的GC日志和pprof工具，介绍GC调优的基本方法。\n本有还有如下的不足：未对逃逸分析和池化对象给出具体的示例。\n4 参考 [1]Garbage Collection In Go : Part II - GC Traces， https://www.ardanlabs.com/blog/2019/05/garbage-collection-in-go-part2-gctraces.html\n[2]Getting to Go: The Journey of Go\u0026rsquo;s Garbage Collector, https://blog.golang.org/ismmkeynote\n[3] Golang GC核心要点和度量方法, https://wudaijun.com/2020/01/go-gc-keypoint-and-monitor/\n[4] Go memory ballast: How I learnt to stop worrying and love the heap, https://blog.twitch.tv/en/2019/04/10/go-memory-ballast-how-i-learnt-to-stop-worrying-and-love-the-heap-26c2462549a2/\n5 附录 5.1 对GODEBUG=gctrace=1信息的解读 gctrace的日志格式为： gc # @#s #%: #+#+# ms clock, #+#/#/#+# ms cpu, #-\u0026gt;#-\u0026gt;# MB, # MB goal, # P 其中各个参数的含义如下: gc # 程序启动以来的GC次数 @#s 程序启动了多久 #% GC过程各个阶段的wall time，分别是sweep termination阶段/mark阶段/mark termination阶段 #+...+# GC消耗的CPU时间，分别是gc assist时间/后台gc时间/idle gc时间 #-\u0026gt;#-\u0026gt;# MB GC开始/结束/最后存活的内存 # MB goal 下次触发GC的堆内存大小 # P 一共使用了几个P ","permalink":"https://tianyuxue.github.io/posts/golang-gc/","summary":"\u003cblockquote\u003e\n\u003cp\u003e本文介绍了Golang中GC的执行过程，然后用一个例子，结合golang提供的GC日志和pprof工具，介绍GC调优的基本方法\u003c/p\u003e\n\u003cp\u003e本文的讨论基于golang 1.15.4版本\u003c/p\u003e\n\u003c/blockquote\u003e","title":"关于Golang GC的一些分析"},{"content":" 本文主要从实践的角度讨论了Golang中调度器工作的不同时机和处理方法\n本文的讨论基于golang 1.15.4版本\n 1 概述 golang目前版本(1.15)使用了GMP调度模型，本文主要从实践的角度去理解golang调度器的一些原理，关于调度理论的详细解释，可以参考如下资源：\n 关于调度原理的理论讲解可以参考链接[1] golang也提供了trace工具来收集调度数据，具体使用可以参考链接[2] 对于trace信息的解释，可以参考本文的附录，也可以参考[3]  2 触发调度的时机以及处理方法 调度是为了保证cpu等物理资源得到充分的利用，那什么时候需要触发调度呢？答案一定是用户代码无法充分利用cpu等物理资源的时候才触发。通过调度这种方式，把cpu等物理资源的使用权让给其他调度单位，增加用户代码的执行效率。\n对于线程或者协程而言，阻塞会导致物理资源的占用，无法执行其他待执行的用户代码，因此阻塞是触发调度的主要原因。除此之外，为了避免饥饿(Starvation)而使用的公平调度算法也会触发调度。在golang中常见的触发调度的事件有如下几种：\n 阻塞式系统调用 非阻塞系统调用 读写channel mutex的加锁和释放锁 定时器 公平调度算法引发的调度（本文暂未分析)  下面对上述情况依次进行分析。\n2.1 阻塞式系统调用引发的调度 首先思考如果Goroutine进行了阻塞式的系统调用会发生什么？为了增加物理资源的使用率，这个时候应该触发调度，把物理资源让给其他Goroutine执行。那调度相关的逻辑处理怎么嵌入到系统调用中呢？golang的syscall包对系统调用进行了封装，在系统调用前后增加了部分调度相关的逻辑。以x86平台为例，具体实现位于**/src/syscall/asm_linux_amd64.s** 中 ， 代码如下：\n对系统调用的封装\n可以看到，golang使用了类似代理模式，在系统调用前后分别插入了如下函数：\n runtime.entersyscall() runtime.exitsyscall()  那么这两个函数做了什么呢？\n runtime.entersyscall() 实现了如下逻辑：  由于进行了系统调用，当前M（Machine）会阻塞 当前G对应的P(Processor)会与当前M(Machine）解绑 当前G对应的P(Processor)会绑定到一个其他可用M(Machine)上，继续执行P自己的任务队列中的其他G(groutines) 经过上面三步，本质上是新启动了一个内核线程继续执行P中未完成的工作，原线程阻塞等待系统调用的结束。golang通过这种方式保证了物理资源的充分利用  这部分逻辑位于/src/runtime/proc.c中：      entersyscall() 函数\n runtime.exitsyscall() 实现了如下逻辑：  当系统调用完成，G变为Runnable状态，exitsyscall()会调用mcall() 触发一个调度事件，把G放在可用的P中的任务队列中，等待执行 这部分代码位同样位于/src/runtime/proc.c中    exitsyscall() 函数\n2.1.1 验证阻塞式系统调用导致的M与P解绑 下面通过一个简单的示例来验证上面所说的理论是否正确，示例代码如下，代码功能可以参考注释：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59  package main  import (  \u0026#34;fmt\u0026#34;  \u0026#34;net\u0026#34;  \u0026#34;sync\u0026#34;  \u0026#34;time\u0026#34; )  func main() {  stopChan := make(chan struct{})  wg := sync.WaitGroup{}  wg.Add(1) \t// 2秒钟后停止 InfnityLoop  go func() {  timer := time.NewTimer(2 * time.Second)  \u0026lt;-timer.C  close(stopChan)  }()   go func() {  defer wg.Done()  sysCall(stopChan)  }()   wg.Wait() }  /** * sysCall函数首先执行一个无限循环模拟cpu占用 * 2秒后停止循环，进行一个阻塞5秒的iowait系统调用 * 系统调用完成后继续进行无限循环 */ func sysCall(stopChan chan struct{}) {  // 首先开始无限循环，模拟cpu占用  infinitLoop(stopChan)   fmt.Println(\u0026#34;begin syscall\u0026#34;)  // 这里通过对一个不存在的地址进行tcp连接来模拟耗时的阻塞式系统调用  _, err := net.DialTimeout(\u0026#34;tcp\u0026#34;, \u0026#34;172.20.4.111:80\u0026#34;, 5 *time.Second)  if err != nil {  fmt.Println(err.Error())  }  fmt.Println(\u0026#34;finish syscall\u0026#34;)   // 系统调用结束后继续循环，模拟cpu占用  ch := make(chan struct{})  infinitLoop(ch) }  func infinitLoop(stopChan chan struct{}) {  for {  select {  case \u0026lt;-stopChan:  return  default:  }  } }   执行如下命令编译、运行代码， 指定系统使用2个P（Processor）, 每秒输出一次调度信息：\n1 2  go build main.go GOMAXPROCS=2 GODEBUG=schedtrace=1000,scheddetail=1 ./main   程序执行大概10秒后按下ctrl + c 终止程序，可以得到如下输出(各个字段的具体含义可参考附录)：\n系统调用后M与P解绑\n从上图的输出中可以得到如下结论：\n 系统调用之前  代码1处可以看出P1处于运行状态(status=1) 代码2处可以看出M0正在与P1绑定，并且正在执行id为20的Goroutine   在系统调用完成之前  代码3处可以看到由于系统调用，P1已经处于idle状态 代码4处可以看到由于系统调用，M0已经空闲(p=-1, curg=-1)，不再与P1绑定 代码5处可以看到此时G处于阻塞状态(status=4), 并且阻塞的原因是IO wait     在系统调用完成之后可以看到（上图）  由于代码中的infinityLoop()函数，P0恢复为运行状态(status=1) M0重新与P0绑定，开始执行用户代码(p=0 curg=20)    总结：可以看出，阻塞式的系统调用会引起M，与P的解绑，golang正是通过这种方式保证了groutine的并发度不被系统调用给阻塞掉，以达到充分利用物理资源的目的。M与P解绑和重新绑定是通过操作系统的内核线程切换完成的，因此这种情况下调度的本质是真正的线程上下文切换。\n2.2 其他情况下的调度 2.2.1 非阻塞式系统调用引发的调度 Golang处理并发的编程范式是：将所有的外部调用都进行阻塞式的处理，通过goroutine和channel来处理阻塞调用的并发问题，这与其他语言使用future和callback是完全不同的思路。通过2.1部分可以看出，每一次阻塞式的系统调用都会新建一个内核线程并且进行线程切换，这种方案在频繁进行系统调用时候会发生什么呢？显而易见的，大量的内核线程会被创建出来，并且随着系统调用开始和结束，不断的进行线程上下文切换。这个问题在golang的http server中尤为明显，试想一下，如果golang的http server使用这种方案，是不是一夜回到解放前的BIO线程模型了？当前主流的网络框架的IO模型都使用IO多路复用模型，具体而言就是依靠epoll/kquue/IOCP等系统调用，使用Reactor模式处理网络请求，比如大名鼎鼎的Netty 网络框架。\ngolang在这方面是如何做的呢？net/http 包实现了名为netpoller 的结构体，进行了如下的工作：\n netpoller 使用epoll/kqueue/IOCP等非阻塞系统调用等待IO事件的到来 真正处理请求的goroutine阻塞在netpoller上 有IO事件到来时候netpooler就通知阻塞的goroutine开始工作  可以看出，netpooler实际上是一个非阻塞调用与阻塞调用之间的转换器，将非阻塞的系统调用成功应用在了golang使用阻塞goroutine+channel的编程范式上了。 而这种由netpooler引发的调度，实际上操作系统的内核线程是无感的，从内核线程的视角看，执行的都是连续的内核空间代码。\n还有一个问题，就是netpooler是什么时候启动的呢？\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  runtime/proc.go:110  func main() {  ...   if GOARCH != \u0026#34;wasm\u0026#34; { // no threads on wasm yet, so no sysmon  systemstack(func() {  newm(sysmon, nil) // 在程序启动时候，启动sysmon m  })  }   // Lock the main goroutine onto this, the main OS thread,  // during initialization. Most programs won\u0026#39;t care, but a few  // do require certain calls to be made by the main thread.  // Those can arrange for main.main to run in the main thread  // by calling runtime.LockOSThread during initialization  // to preserve the lock.  lockOSThread()  ... }    编译好的程序入口位于\u0026quot;**runtime/proc.go**\u0026quot;， 执行main()函数时候会启动sysmon, 并绑定到一个M上执行 sysmon()函数会启动netpoller  2.2.2 读取channel以及互斥锁引发的调度 对于channel和锁等待操作，同样都是在用户空间完成的。大致原理如下：\n channel拥有两个队列存储阻塞的goroutine, 这些goroutine阻塞在接收和发送数据的状态 mutex也同样有队列存储阻塞等待的goroutine 一旦阻塞条件接触，阻塞的goroutine 就变为runnable 状态，加入到某个P的任务队列中  这部分的调度同样对操作系统内核线程是透明的，内核线程认为自己只是在执行用户空间代码，完全没有线程阻塞和上下文切换。\n3 结论 通过上述讨论，可以将golang的调度主要分为以下两种：\n 阻塞式系统调用会触发真正的线程上下文切换 netpoller、读写channel、获取锁等操作引发的调度只在用户空间完成，操作系统对此是无感的，这也正是golang这门语言简单，高效的原因的之一。  4 不足 本文未探讨golang调度器提供的一些公平调度方案。\n对具体的GMP的调度算法未做深入探究。\n参考 [1] Illustrated Tales of Go Runtime Scheduler. https://medium.com/@ankur_anand/illustrated-tales-of-go-runtime-scheduler-74809ef6d19b\n[2] go tool trace. https://making.pusher.com/go-tool-trace\n[3] Looking at Scheduling Tracking with GODEBUG. https://programming.vip/docs/looking-at-scheduling-tracking-with-godebug.html\n[4] 也谈goroutine调度器. https://tonybai.com/2017/06/23/an-intro-about-goroutine-scheduler/\n[5] Linux 的 I/O 模型以及 Go 的网络模型实现. https://xiaoxubeii.github.io/articles/linux-io-models-and-go-network-model-2/\n[6] golang netpoller. https://yizhi.ren/2019/06/08/gonetpoller/\n附录： scheddetail 参数说明 设置了godebug=scheddetail=1 情况下，假设示例输出如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  $ GODEBUG=scheddetail=1,schedtrace=1000 ./main SCHED 1000ms: gomaxprocs=4 idleprocs=0 threads=5 spinningthreads=0 idlethreads=0 runqueue=0 gcwaiting=0 nmidlelocked=0 stopwait=0 sysmonwait=0  P0: status=1 schedtick=2 syscalltick=0 m=3 runqsize=3 gfreecnt=0  P1: status=1 schedtick=2 syscalltick=0 m=4 runqsize=1 gfreecnt=0  P2: status=1 schedtick=2 syscalltick=0 m=0 runqsize=1 gfreecnt=0  P3: status=1 schedtick=1 syscalltick=0 m=2 runqsize=1 gfreecnt=0  M4: p=1 curg=18 mallocing=0 throwing=0 preemptoff= locks=0 dying=0 spinning=false blocked=false lockedg=-1  M3: p=0 curg=22 mallocing=0 throwing=0 preemptoff= locks=0 dying=0 spinning=false blocked=false lockedg=-1  M2: p=3 curg=24 mallocing=0 throwing=0 preemptoff= locks=0 dying=0 spinning=false blocked=false lockedg=-1  M1: p=-1 curg=-1 mallocing=0 throwing=0 preemptoff= locks=1 dying=0 spinning=false blocked=false lockedg=-1  M0: p=2 curg=26 mallocing=0 throwing=0 preemptoff= locks=0 dying=0 spinning=false blocked=false lockedg=-1  G1: status=4(semacquire) m=-1 lockedm=-1  G2: status=4(force gc (idle)) m=-1 lockedm=-1  G3: status=4(GC sweep wait) m=-1 lockedm=-1  G17: status=1() m=-1 lockedm=-1  G18: status=2() m=4 lockedm=-1  G19: status=1() m=-1 lockedm=-1  G20: status=1() m=-1 lockedm=-1  G21: status=1() m=-1 lockedm=-1  G22: status=2() m=3 lockedm=-1  G23: status=1() m=-1 lockedm=-1  G24: status=2() m=2 lockedm=-1  G25: status=1() m=-1 lockedm=-1  G26: status=2() m=0 lockedm=-1   G的信息如下：\n status： G的状态 m：属于哪那个M lockedm：M是否被锁定 G的状态表位于文件runtime2.go  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49  // defined constants const ( \t// G status \t// ... \t// _Gidle means this goroutine was just allocated and has not \t// yet been initialized. \t_Gidle = iota // 0 \t// _Grunnable means this goroutine is on a run queue. It is \t// not currently executing user code. The stack is not owned. \t_Grunnable // 1 \t// _Grunning means this goroutine may execute user code. The \t// stack is owned by this goroutine. It is not on a run queue. \t// It is assigned an M and a P (g.m and g.m.p are valid). \t_Grunning // 2 \t// _Gsyscall means this goroutine is executing a system call. \t// It is not executing user code. The stack is owned by this \t// goroutine. It is not on a run queue. It is assigned an M. \t_Gsyscall // 3 \t// _Gwaiting means this goroutine is blocked in the runtime. \t// It is not executing user code. It is not on a run queue, \t// but should be recorded somewhere (e.g., a channel wait \t// queue) so it can be ready()d when necessary. The stack is \t// not owned *except* that a channel operation may read or \t// write parts of the stack under the appropriate channel \t// lock. Otherwise, it is not safe to access the stack after a \t// goroutine enters _Gwaiting (e.g., it may get moved). \t_Gwaiting // 4 \t// _Gmoribund_unused is currently unused, but hardcoded in gdb \t// scripts. \t_Gmoribund_unused // 5 \t// _Gdead means this goroutine is currently unused. It may be \t// just exited, on a free list, or just being initialized. It \t// is not executing user code. It may or may not have a stack \t// allocated. The G and its stack (if any) are owned by the M \t// that is exiting the G or that obtained the G from the free \t// list. \t_Gdead // 6 \t// _Genqueue_unused is currently unused. \t_Genqueue_unused // 7 \t// _Gcopystack means this goroutine\u0026#39;s stack is being moved. It \t// is not executing user code and is not on a run queue. The \t// stack is owned by the goroutine that put it in _Gcopystack. \t_Gcopystack // 8 \t// _Gpreempted means this goroutine stopped itself for a \t// suspendG preemption. It is like _Gwaiting, but nothing is \t// yet responsible for ready()ing it. Some suspendG must CAS \t// the status to _Gwaiting to take responsibility for \t// ready()ing this G. \t_Gpreempted // 9    G阻塞的原因如下  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  runtime2.go  const ( waitReasonZero waitReason = iota // \u0026#34;\u0026#34; waitReasonGCAssistMarking // \u0026#34;GC assist marking\u0026#34; waitReasonIOWait // \u0026#34;IO wait\u0026#34; waitReasonChanReceiveNilChan // \u0026#34;chan receive (nil chan)\u0026#34; waitReasonChanSendNilChan // \u0026#34;chan send (nil chan)\u0026#34; waitReasonDumpingHeap // \u0026#34;dumping heap\u0026#34; waitReasonGarbageCollection // \u0026#34;garbage collection\u0026#34; waitReasonGarbageCollectionScan // \u0026#34;garbage collection scan\u0026#34; waitReasonPanicWait // \u0026#34;panicwait\u0026#34; waitReasonSelect // \u0026#34;select\u0026#34; waitReasonSelectNoCases // \u0026#34;select (no cases)\u0026#34; waitReasonGCAssistWait // \u0026#34;GC assist wait\u0026#34; waitReasonGCSweepWait // \u0026#34;GC sweep wait\u0026#34; waitReasonGCScavengeWait // \u0026#34;GC scavenge wait\u0026#34; waitReasonChanReceive // \u0026#34;chan receive\u0026#34; waitReasonChanSend // \u0026#34;chan send\u0026#34; waitReasonFinalizerWait // \u0026#34;finalizer wait\u0026#34; waitReasonForceGCIdle // \u0026#34;force gc (idle)\u0026#34; waitReasonSemacquire // \u0026#34;semacquire\u0026#34; waitReasonSleep // \u0026#34;sleep\u0026#34; waitReasonSyncCondWait // \u0026#34;sync.Cond.Wait\u0026#34; waitReasonTimerGoroutineIdle // \u0026#34;timer goroutine (idle)\u0026#34; waitReasonTraceReaderBlocked // \u0026#34;trace reader (blocked)\u0026#34; waitReasonWaitForGCCycle // \u0026#34;wait for GC cycle\u0026#34; waitReasonGCWorkerIdle // \u0026#34;GC worker (idle)\u0026#34; waitReasonPreempted // \u0026#34;preempted\u0026#34; waitReasonDebugCall // \u0026#34;debug call\u0026#34; )   M的信息如下：\n P: 当前与哪个P绑定 curg: 当前执行哪个G gfreecnt: 可用的 G (Gdead state). mallocing: 是否在分配内存 Throwing: 是否抛出了一场 preemptoff: 如果非空，当前执行的G不会被抢占  P的信息如下：\n status: 运行状态 Schedule tick: 调度次数 syscalltick: 系统调用的次数 M: 与哪个M进行绑定 runqsize: 运行队列的大小 gfreecnt: 可用的 G (Gdead state). P的状态表如下：  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44  const ( \t// P status \t// _Pidle means a P is not being used to run user code or the \t// scheduler. Typically, it\u0026#39;s on the idle P list and available \t// to the scheduler, but it may just be transitioning between \t// other states. \t// \t// The P is owned by the idle list or by whatever is \t// transitioning its state. Its run queue is empty. \t_Pidle = iota \t// _Prunning means a P is owned by an M and is being used to \t// run user code or the scheduler. Only the M that owns this P \t// is allowed to change the P\u0026#39;s status from _Prunning. The M \t// may transition the P to _Pidle (if it has no more work to \t// do), _Psyscall (when entering a syscall), or _Pgcstop (to \t// halt for the GC). The M may also hand ownership of the P \t// off directly to another M (e.g., to schedule a locked G). \t_Prunning \t// _Psyscall means a P is not running user code. It has \t// affinity to an M in a syscall but is not owned by it and \t// may be stolen by another M. This is similar to _Pidle but \t// uses lightweight transitions and maintains M affinity. \t// \t// Leaving _Psyscall must be done with a CAS, either to steal \t// or retake the P. Note that there\u0026#39;s an ABA hazard: even if \t// an M successfully CASes its original P back to _Prunning \t// after a syscall, it must understand the P may have been \t// used by another M in the interim. \t_Psyscall \t// _Pgcstop means a P is halted for STW and owned by the M \t// that stopped the world. The M that stopped the world \t// continues to use its P, even in _Pgcstop. Transitioning \t// from _Prunning to _Pgcstop causes an M to release its P and \t// park. \t// \t// The P retains its run queue and startTheWorld will restart \t// the scheduler on Ps with non-empty run queues. \t_Pgcstop \t// _Pdead means a P is no longer used (GOMAXPROCS shrank). We \t// reuse Ps if GOMAXPROCS increases. A dead P is mostly \t// stripped of its resources, though a few things remain \t// (e.g., trace buffers). \t_Pdead )   ","permalink":"https://tianyuxue.github.io/posts/golang-scheduler/","summary":"\u003cblockquote\u003e\n\u003cp\u003e本文主要从实践的角度讨论了Golang中调度器工作的不同时机和处理方法\u003c/p\u003e\n\u003cp\u003e本文的讨论基于golang 1.15.4版本\u003c/p\u003e\n\u003c/blockquote\u003e","title":"关于Golang调度器的一些分析"}]
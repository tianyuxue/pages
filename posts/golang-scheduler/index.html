<!doctype html><html lang=zh-cn>
<head>
<meta charset=utf-8>
<meta http-equiv=x-ua-compatible content="IE=edge,chrome=1">
<title>关于Golang调度器的一些分析 | ACoder</title>
<meta name=viewport content="width=device-width,minimum-scale=1">
<meta name=description content="
本文主要从实践的角度讨论了Golang中调度器工作的不同时机和处理方法
本文的讨论基于golang 1.15.4版本
">
<meta name=generator content="Hugo 0.92.0">
<meta name=ROBOTS content="NOINDEX, NOFOLLOW">
<link rel=stylesheet href=/ananke/css/main.min.css>
<link rel="shortcut icon" href=/images/code.png type=image/x-icon>
<meta property="og:title" content="关于Golang调度器的一些分析">
<meta property="og:description" content="
本文主要从实践的角度讨论了Golang中调度器工作的不同时机和处理方法
本文的讨论基于golang 1.15.4版本
">
<meta property="og:type" content="article">
<meta property="og:url" content="https://tianyuxue.github.io/posts/golang-scheduler/"><meta property="article:section" content="posts">
<meta property="article:published_time" content="2020-12-26T00:00:00+00:00">
<meta property="article:modified_time" content="2020-12-26T00:00:00+00:00">
<meta itemprop=name content="关于Golang调度器的一些分析">
<meta itemprop=description content="
本文主要从实践的角度讨论了Golang中调度器工作的不同时机和处理方法
本文的讨论基于golang 1.15.4版本
"><meta itemprop=datePublished content="2020-12-26T00:00:00+00:00">
<meta itemprop=dateModified content="2020-12-26T00:00:00+00:00">
<meta itemprop=wordCount content="1456">
<meta itemprop=keywords content="golang,调度器,"><meta name=twitter:card content="summary">
<meta name=twitter:title content="关于Golang调度器的一些分析">
<meta name=twitter:description content="
本文主要从实践的角度讨论了Golang中调度器工作的不同时机和处理方法
本文的讨论基于golang 1.15.4版本
">
</head>
<body class="ma0 avenir bg-near-white">
<header class="cover bg-top" style=background-image:url(https://tianyuxue.github.io/images/cropped-valais-3562988_1920-2.jpg)>
<div class="pb3-m pb6-l bg-black-10">
<nav class="pv3 ph3 ph4-ns" role=navigation>
<div class="flex-l justify-between items-center center">
<a href=/ class="f3 fw2 hover-white no-underline white-90 dib">
<img src=/images/cropped-code.png class="w100 mw5-ns" alt=ACoder>
</a>
<div class="flex-l items-center">
<ul class="pl0 mr3">
<li class="list f5 f4-ns fw4 dib pr3">
<a class="hover-white no-underline white-90" href=/posts/ title="文章 page">
文章
</a>
</li>
<li class="list f5 f4-ns fw4 dib pr3">
<a class="hover-white no-underline white-90" href=/about/ title="关于我 page">
关于我
</a>
</li>
</ul>
<div class=ananke-socials>
<a href=https://github.com/tianyuxue target=_blank class="github ananke-social-link link-transition stackoverflow link dib z-999 pt3 pt0-l mr1" title="GitHub link" rel=noopener aria-label="follow on GitHub——Opens in a new window">
<span class=icon><svg style="enable-background:new 0 0 512 512" viewBox="0 0 512 512" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M256 32C132.3 32 32 134.8 32 261.7c0 101.5 64.2 187.5 153.2 217.9 11.2 2.1 15.3-5 15.3-11.1.0-5.5-.2-19.9-.3-39.1-62.3 13.9-75.5-30.8-75.5-30.8-10.2-26.5-24.9-33.6-24.9-33.6-20.3-14.3 1.5-14 1.5-14 22.5 1.6 34.3 23.7 34.3 23.7 20 35.1 52.4 25 65.2 19.1 2-14.8 7.8-25 14.2-30.7-49.7-5.8-102-25.5-102-113.5.0-25.1 8.7-45.6 23-61.6-2.3-5.8-10-29.2 2.2-60.8.0.0 18.8-6.2 61.6 23.5 17.9-5.1 37-7.6 56.1-7.7 19 .1 38.2 2.6 56.1 7.7 42.8-29.7 61.5-23.5 61.5-23.5 12.2 31.6 4.5 55 2.2 60.8 14.3 16.1 23 36.6 23 61.6.0 88.2-52.4 107.6-102.3 113.3 8 7.1 15.2 21.1 15.2 42.5.0 30.7-.3 55.5-.3 63 0 6.1 4 13.3 15.4 11C415.9 449.1 480 363.1 480 261.7 480 134.8 379.7 32 256 32z"/></svg>
</span>
<span class=new-window><svg height="8" style="enable-background:new 0 0 1000 1000" viewBox="0 0 1e3 1e3" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M598 128h298v298h-86V274L392 692l-60-60 418-418H598v-86zM810 810V512h86v298c0 46-40 86-86 86H214c-48 0-86-40-86-86V214c0-46 38-86 86-86h298v86H214v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;fill:"/></svg>
</span></a>
</div>
</div>
</div>
</nav>
<div class="tc-l pv6 ph3 ph4-ns">
<h1 class="f2 f1-l fw2 white-90 mb0 lh-title">关于Golang调度器的一些分析</h1>
</div>
</div>
</header>
<main class=pb7 role=main>
<article class="flex-l flex-wrap justify-between mw8 center ph3">
<header class="mt4 w-100">
<aside class="instapaper_ignoref b helvetica tracked">
POSTS
</aside>
<div id=sharing class="mt3 ananke-socials">
</div>
<h1 class="f1 athelas mt3 mb1">关于Golang调度器的一些分析</h1>
<p class=tracked>
By <strong>
jitianyu
</strong>
</p>
<time class="f6 mv4 dib tracked" datetime=2020-12-26T00:00:00Z>December 26, 2020</time>
<span class="f6 mv4 dib tracked"> - 7 minutes read </span>
<span class="f6 mv4 dib tracked"> - 1456 words </span>
</header>
<div class="nested-copy-line-height lh-copy serif f4 nested-links nested-img mid-gray pr4-l w-two-thirds-l"><blockquote>
<p>本文主要从实践的角度讨论了Golang中调度器工作的不同时机和处理方法</p>
<p>本文的讨论基于golang 1.15.4版本</p>
</blockquote>
<h2 id=1-概述>1 概述</h2>
<p>golang目前版本(1.15)使用了GMP调度模型，本文主要从实践的角度去理解golang调度器的一些原理，关于调度理论的详细解释，可以参考如下资源：</p>
<ul>
<li>关于调度原理的理论讲解可以参考链接<a href=https://medium.com/@ankur_anand/illustrated-tales-of-go-runtime-scheduler-74809ef6d19b>[1]</a></li>
<li>golang也提供了trace工具来收集调度数据，具体使用可以参考链接<a href=https://making.pusher.com/go-tool-trace>[2]</a></li>
<li>对于trace信息的解释，可以参考本文的附录，也可以参考<a href=https://programming.vip/docs/looking-at-scheduling-tracking-with-godebug.html>[3]</a></li>
</ul>
<h2 id=2-触发调度的时机以及处理方法>2 触发调度的时机以及处理方法</h2>
<p>调度是为了保证cpu等物理资源得到充分的利用，那什么时候需要触发调度呢？答案一定是用户代码无法充分利用cpu等物理资源的时候才触发。通过调度这种方式，把cpu等物理资源的使用权让给其他调度单位，增加用户代码的执行效率。</p>
<p>对于线程或者协程而言，阻塞会导致物理资源的占用，无法执行其他待执行的用户代码，因此阻塞是触发调度的主要原因。除此之外，为了避免饥饿(Starvation)而使用的公平调度算法也会触发调度。在golang中常见的触发调度的事件有如下几种：</p>
<ul>
<li>阻塞式系统调用</li>
<li>非阻塞系统调用</li>
<li>读写channel</li>
<li>mutex的加锁和释放锁</li>
<li>定时器</li>
<li>公平调度算法引发的调度（本文暂未分析)</li>
</ul>
<p>下面对上述情况依次进行分析。</p>
<h2 id=21-阻塞式系统调用引发的调度>2.1 阻塞式系统调用引发的调度</h2>
<p>首先思考如果Goroutine进行了阻塞式的系统调用会发生什么？为了增加物理资源的使用率，这个时候应该触发调度，把物理资源让给其他Goroutine执行。那调度相关的逻辑处理怎么嵌入到系统调用中呢？golang的<code>syscall</code>包对系统调用进行了封装，在系统调用前后增加了部分调度相关的逻辑。以x86平台为例，具体实现位于<code>**/src/syscall/asm_linux_amd64.s**</code> 中 ， 代码如下：</p>
<p><img src=images/image-20201224140711356-1.png alt></p>
<p>对系统调用的封装</p>
<p>可以看到，golang使用了类似代理模式，在系统调用前后分别插入了如下函数：</p>
<ul>
<li><code>runtime.entersyscall()</code></li>
<li><code>runtime.exitsyscall()</code></li>
</ul>
<p>那么这两个函数做了什么呢？</p>
<ul>
<li><code>runtime.entersyscall()</code> 实现了如下逻辑：
<ol>
<li>由于进行了系统调用，当前M（Machine）会阻塞</li>
<li>当前G对应的P(Processor)会与当前M(Machine）解绑</li>
<li>当前G对应的P(Processor)会绑定到一个其他可用M(Machine)上，继续执行P自己的任务队列中的其他G(groutines)</li>
<li>经过上面三步，本质上是<strong>新启动了一个内核线程继续执行P中未完成的工作，原线程阻塞等待系统调用的结束</strong>。golang通过这种方式保证了物理资源的充分利用
<ul>
<li>这部分逻辑位于<code>/src/runtime/proc.c</code>中：</li>
</ul>
</li>
</ol>
</li>
</ul>
<p><img src=images/image-20201224141715303.png alt></p>
<p>entersyscall() 函数</p>
<ul>
<li><code>runtime.exitsyscall()</code> 实现了如下逻辑：
<ul>
<li>当系统调用完成，G变为Runnable状态，<code>exitsyscall()</code>会调用<code>mcall()</code> 触发一个调度事件，把G放在可用的P中的任务队列中，等待执行</li>
<li>这部分代码位同样位于<code>/src/runtime/proc.c</code>中</li>
</ul>
</li>
</ul>
<p><img src=images/image-20201224143553971.png alt></p>
<p>exitsyscall() 函数</p>
<h3 id=211-验证阻塞式系统调用导致的m与p解绑>2.1.1 验证阻塞式系统调用导致的M与P解绑</h3>
<p>下面通过一个简单的示例来验证上面所说的理论是否正确，示例代码如下，代码功能可以参考注释：</p>
<p>package main</p>
<p>import (
&ldquo;fmt&rdquo;
&ldquo;net&rdquo;
&ldquo;sync&rdquo;
&ldquo;time&rdquo;
)</p>
<p>func main() {
stopChan := make(chan struct{})
wg := sync.WaitGroup{}
wg.Add(1)
// 2秒钟后停止 InfnityLoop
go func() {
timer := time.NewTimer(2 * time.Second)
&lt;-timer.C
close(stopChan)
}()</p>
<pre><code>go func() {
    defer wg.Done()
    sysCall(stopChan)
}() 

wg.Wait()
</code></pre>
<p>}
/**
* sysCall函数首先执行一个无限循环模拟cpu占用
* 2秒后停止循环，进行一个阻塞5秒的iowait系统调用
* 系统调用完成后继续进行无限循环
*/
func sysCall(stopChan chan struct{}) {
// 首先开始无限循环，模拟cpu占用
infinitLoop(stopChan)</p>
<pre><code>fmt.Println(&quot;begin syscall&quot;)
// 这里通过对一个不存在的地址进行tcp连接来模拟耗时的阻塞式系统调用
\_, err := net.DialTimeout(&quot;tcp&quot;, &quot;172.20.4.111:80&quot;, 5\*time.Second)
if err != nil {
    fmt.Println(err.Error())
}   
fmt.Println(&quot;finish syscall&quot;)

// 系统调用结束后继续循环，模拟cpu占用
ch := make(chan struct{})
infinitLoop(ch)
</code></pre>
<p>}</p>
<p>func infinitLoop(stopChan chan struct{}) {
for {
select {
case &lt;-stopChan:
return
default:
}<br>
}<br>
}</p>
<p>执行如下命令编译、运行代码， 指定系统使用2个P（Processor）, 每秒输出一次调度信息：</p>
<pre tabindex=0><code>go build main.go
GOMAXPROCS=2 GODEBUG=schedtrace=1000,scheddetail=1 ./main
</code></pre><p>程序执行大概10秒后按下<code>ctrl + c</code> 终止程序，可以得到如下输出(各个字段的具体含义可参考附录)：</p>
<p><img src=images/image-20201224151118546.png alt></p>
<p>系统调用后M与P解绑</p>
<p>从上图的输出中可以得到如下结论：</p>
<ul>
<li>系统调用之前
<ul>
<li>代码1处可以看出P1处于运行状态(status=1)</li>
<li>代码2处可以看出M0正在与P1绑定，并且正在执行id为20的Goroutine</li>
</ul>
</li>
<li>在系统调用完成之前
<ul>
<li>代码3处可以看到由于系统调用，P1已经处于idle状态</li>
<li>代码4处可以看到由于系统调用，M0已经空闲(p=-1, curg=-1)，不再与P1绑定</li>
<li>代码5处可以看到此时G处于阻塞状态(status=4), 并且阻塞的原因是IO wait</li>
</ul>
</li>
</ul>
<p><img src=images/image-20201224152456128.png alt></p>
<ul>
<li>在系统调用完成之后可以看到（上图）
<ul>
<li>由于代码中的<code>infinityLoop()</code>函数，P0恢复为运行状态(status=1)</li>
<li>M0重新与P0绑定，开始执行用户代码(p=0 curg=20)</li>
</ul>
</li>
</ul>
<p>总结：可以看出，阻塞式的系统调用会引起M，与P的解绑，golang正是通过这种方式保证了groutine的并发度不被系统调用给阻塞掉，以达到充分利用物理资源的目的。<strong>M与P解绑和重新绑定是通过操作系统的内核线程切换完成的，因此这种情况下调度的本质是真正的线程上下文切换。</strong></p>
<h2 id=22-其他情况下的调度>2.2 其他情况下的调度</h2>
<h3 id=221-非阻塞式系统调用引发的调度>2.2.1 非阻塞式系统调用引发的调度</h3>
<p>Golang处理并发的编程范式是：<strong>将所有的外部调用都进行阻塞式的处理，通过goroutine和channel来处理阻塞调用的并发问题</strong>，这与其他语言使用future和callback是完全不同的思路。通过2.1部分可以看出，每一次阻塞式的系统调用都会新建一个内核线程并且进行线程切换，这种方案在频繁进行系统调用时候会发生什么呢？显而易见的，大量的内核线程会被创建出来，并且随着系统调用开始和结束，不断的进行线程上下文切换。这个问题在golang的http server中尤为明显，试想一下，如果golang的http server使用这种方案，是不是一夜回到解放前的BIO线程模型了？当前主流的网络框架的IO模型都使用IO多路复用模型，具体而言就是依靠<code>epoll/kquue/IOCP</code>等系统调用，使用Reactor模式处理网络请求，比如大名鼎鼎的<code>Netty</code> 网络框架。</p>
<p>golang在这方面是如何做的呢？<code>net/http</code> 包实现了名为<code>netpoller</code> 的结构体，进行了如下的工作：</p>
<ul>
<li><code>netpoller</code> 使用<code>epoll/kqueue/IOCP</code>等非阻塞系统调用等待IO事件的到来</li>
<li>真正处理请求的goroutine阻塞在netpoller上</li>
<li>有IO事件到来时候<code>netpooler</code>就通知阻塞的goroutine开始工作</li>
</ul>
<p>可以看出，<code>netpooler</code>实际上是一个非阻塞调用与阻塞调用之间的转换器，将非阻塞的系统调用成功应用在了<strong>golang使用阻塞goroutine+channel的编程范式上了。</strong> 而这种由netpooler引发的调度，实际上<strong>操作系统的内核线程是无感的，从内核线程的视角看，执行的都是连续的内核空间代码。</strong></p>
<p>还有一个问题，就是netpooler是什么时候启动的呢？</p>
<p>runtime/proc.go:110</p>
<p>func main() {
&mldr;</p>
<pre><code>if GOARCH != &quot;wasm&quot; { // no threads on wasm yet, so no sysmon
    systemstack(func() {
        newm(sysmon, nil) // 在程序启动时候，启动sysmon m
    })
}

// Lock the main goroutine onto this, the main OS thread,
// during initialization. Most programs won't care, but a few
// do require certain calls to be made by the main thread.
// Those can arrange for main.main to run in the main thread
// by calling runtime.LockOSThread during initialization
// to preserve the lock.
lockOSThread()
...
</code></pre>
<p>}</p>
<ul>
<li>编译好的程序入口位于"<code>**runtime/proc.go**"</code>， 执行<code>main()</code>函数时候会启动<code>sysmon</code>, 并绑定到一个M上执行</li>
<li><code>sysmon()</code>函数会启动<code>netpoller</code></li>
</ul>
<h3 id=222-读取channel以及互斥锁引发的调度>2.2.2 读取channel以及互斥锁引发的调度</h3>
<p>对于channel和锁等待操作，同样都是在用户空间完成的。大致原理如下：</p>
<ul>
<li>channel拥有两个队列存储阻塞的goroutine, 这些goroutine阻塞在接收和发送数据的状态</li>
<li><code>mutex</code>也同样有队列存储阻塞等待的goroutine</li>
<li>一旦阻塞条件接触，阻塞的<code>goroutine</code> 就变为<code>runnable</code> 状态，加入到某个P的任务队列中</li>
</ul>
<p>这部分的调度同样对操作系统内核线程是透明的，内核线程认为自己只是在执行用户空间代码，完全没有线程阻塞和上下文切换。</p>
<h2 id=3-结论>3 结论</h2>
<p>通过上述讨论，可以将golang的调度主要分为以下两种：</p>
<ul>
<li>阻塞式系统调用会触发真正的线程上下文切换</li>
<li>netpoller、读写channel、获取锁等操作引发的调度只在用户空间完成，操作系统对此是无感的，这也正是golang这门语言简单，高效的原因的之一。</li>
</ul>
<h2 id=4-不足>4 不足</h2>
<p>本文未探讨golang调度器提供的一些公平调度方案。</p>
<p>对具体的GMP的调度算法未做深入探究。</p>
<h1 id=参考>参考</h1>
<p>[1] Illustrated Tales of Go Runtime Scheduler. <a href=https://medium.com/@ankur_anand/illustrated-tales-of-go-runtime-scheduler-74809ef6d19b>https://medium.com/@ankur_anand/illustrated-tales-of-go-runtime-scheduler-74809ef6d19b</a></p>
<p>[2] go tool trace. <a href=https://making.pusher.com/go-tool-trace>https://making.pusher.com/go-tool-trace</a></p>
<p>[3] Looking at Scheduling Tracking with GODEBUG. <a href=https://programming.vip/docs/looking-at-scheduling-tracking-with-godebug.html>https://programming.vip/docs/looking-at-scheduling-tracking-with-godebug.html</a></p>
<p>[4] 也谈goroutine调度器. <a href=https://tonybai.com/2017/06/23/an-intro-about-goroutine-scheduler/>https://tonybai.com/2017/06/23/an-intro-about-goroutine-scheduler/</a></p>
<p>[5] Linux 的 I/O 模型以及 Go 的网络模型实现. <a href=https://xiaoxubeii.github.io/articles/linux-io-models-and-go-network-model-2/>https://xiaoxubeii.github.io/articles/linux-io-models-and-go-network-model-2/</a></p>
<p>[6] golang netpoller. <a href=https://yizhi.ren/2019/06/08/gonetpoller/>https://yizhi.ren/2019/06/08/gonetpoller/</a></p>
<h2 id=附录>附录：</h2>
<h3 id=scheddetail-参数说明>scheddetail 参数说明</h3>
<p>设置了<code>godebug=scheddetail=1</code> 情况下，假设示例输出如下：</p>
<p>$ GODEBUG=scheddetail=1,schedtrace=1000 ./main
SCHED 1000ms: gomaxprocs=4 idleprocs=0 threads=5 spinningthreads=0 idlethreads=0 runqueue=0 gcwaiting=0 nmidlelocked=0 stopwait=0 sysmonwait=0
P0: status=1 schedtick=2 syscalltick=0 m=3 runqsize=3 gfreecnt=0
P1: status=1 schedtick=2 syscalltick=0 m=4 runqsize=1 gfreecnt=0
P2: status=1 schedtick=2 syscalltick=0 m=0 runqsize=1 gfreecnt=0
P3: status=1 schedtick=1 syscalltick=0 m=2 runqsize=1 gfreecnt=0
M4: p=1 curg=18 mallocing=0 throwing=0 preemptoff= locks=0 dying=0 spinning=false blocked=false lockedg=-1
M3: p=0 curg=22 mallocing=0 throwing=0 preemptoff= locks=0 dying=0 spinning=false blocked=false lockedg=-1
M2: p=3 curg=24 mallocing=0 throwing=0 preemptoff= locks=0 dying=0 spinning=false blocked=false lockedg=-1
M1: p=-1 curg=-1 mallocing=0 throwing=0 preemptoff= locks=1 dying=0 spinning=false blocked=false lockedg=-1
M0: p=2 curg=26 mallocing=0 throwing=0 preemptoff= locks=0 dying=0 spinning=false blocked=false lockedg=-1
G1: status=4(semacquire) m=-1 lockedm=-1
G2: status=4(force gc (idle)) m=-1 lockedm=-1
G3: status=4(GC sweep wait) m=-1 lockedm=-1
G17: status=1() m=-1 lockedm=-1
G18: status=2() m=4 lockedm=-1
G19: status=1() m=-1 lockedm=-1
G20: status=1() m=-1 lockedm=-1
G21: status=1() m=-1 lockedm=-1
G22: status=2() m=3 lockedm=-1
G23: status=1() m=-1 lockedm=-1
G24: status=2() m=2 lockedm=-1
G25: status=1() m=-1 lockedm=-1
G26: status=2() m=0 lockedm=-1</p>
<p>G的信息如下：</p>
<ul>
<li>status： G的状态</li>
<li>m：属于哪那个M</li>
<li>lockedm：M是否被锁定</li>
<li>G的状态表位于文件<code>runtime2.go</code></li>
</ul>
<p>// defined constants
const (
// G status
// &mldr;
// _Gidle means this goroutine was just allocated and has not
// yet been initialized.
_Gidle = iota // 0
// _Grunnable means this goroutine is on a run queue. It is
// not currently executing user code. The stack is not owned.
_Grunnable // 1
// _Grunning means this goroutine may execute user code. The
// stack is owned by this goroutine. It is not on a run queue.
// It is assigned an M and a P (g.m and g.m.p are valid).
_Grunning // 2
// _Gsyscall means this goroutine is executing a system call.
// It is not executing user code. The stack is owned by this
// goroutine. It is not on a run queue. It is assigned an M.
_Gsyscall // 3
// _Gwaiting means this goroutine is blocked in the runtime.
// It is not executing user code. It is not on a run queue,
// but should be recorded somewhere (e.g., a channel wait
// queue) so it can be ready()d when necessary. The stack is
// not owned *except* that a channel operation may read or
// write parts of the stack under the appropriate channel
// lock. Otherwise, it is not safe to access the stack after a
// goroutine enters _Gwaiting (e.g., it may get moved).
_Gwaiting // 4
// _Gmoribund_unused is currently unused, but hardcoded in gdb
// scripts.
_Gmoribund_unused // 5
// _Gdead means this goroutine is currently unused. It may be
// just exited, on a free list, or just being initialized. It
// is not executing user code. It may or may not have a stack
// allocated. The G and its stack (if any) are owned by the M
// that is exiting the G or that obtained the G from the free
// list.
_Gdead // 6
// _Genqueue_unused is currently unused.
_Genqueue_unused // 7
// _Gcopystack means this goroutine&rsquo;s stack is being moved. It
// is not executing user code and is not on a run queue. The
// stack is owned by the goroutine that put it in _Gcopystack.
_Gcopystack // 8
// _Gpreempted means this goroutine stopped itself for a
// suspendG preemption. It is like _Gwaiting, but nothing is
// yet responsible for ready()ing it. Some suspendG must CAS
// the status to _Gwaiting to take responsibility for
// ready()ing this G.
_Gpreempted // 9</p>
<ul>
<li>G阻塞的原因如下</li>
</ul>
<p>runtime2.go</p>
<p>const (
waitReasonZero waitReason = iota // ""
waitReasonGCAssistMarking // &ldquo;GC assist marking&rdquo;
waitReasonIOWait // &ldquo;IO wait&rdquo;
waitReasonChanReceiveNilChan // &ldquo;chan receive (nil chan)&rdquo;
waitReasonChanSendNilChan // &ldquo;chan send (nil chan)&rdquo;
waitReasonDumpingHeap // &ldquo;dumping heap&rdquo;
waitReasonGarbageCollection // &ldquo;garbage collection&rdquo;
waitReasonGarbageCollectionScan // &ldquo;garbage collection scan&rdquo;
waitReasonPanicWait // &ldquo;panicwait&rdquo;
waitReasonSelect // &ldquo;select&rdquo;
waitReasonSelectNoCases // &ldquo;select (no cases)&rdquo;
waitReasonGCAssistWait // &ldquo;GC assist wait&rdquo;
waitReasonGCSweepWait // &ldquo;GC sweep wait&rdquo;
waitReasonGCScavengeWait // &ldquo;GC scavenge wait&rdquo;
waitReasonChanReceive // &ldquo;chan receive&rdquo;
waitReasonChanSend // &ldquo;chan send&rdquo;
waitReasonFinalizerWait // &ldquo;finalizer wait&rdquo;
waitReasonForceGCIdle // &ldquo;force gc (idle)&rdquo;
waitReasonSemacquire // &ldquo;semacquire&rdquo;
waitReasonSleep // &ldquo;sleep&rdquo;
waitReasonSyncCondWait // &ldquo;sync.Cond.Wait&rdquo;
waitReasonTimerGoroutineIdle // &ldquo;timer goroutine (idle)&rdquo;
waitReasonTraceReaderBlocked // &ldquo;trace reader (blocked)&rdquo;
waitReasonWaitForGCCycle // &ldquo;wait for GC cycle&rdquo;
waitReasonGCWorkerIdle // &ldquo;GC worker (idle)&rdquo;
waitReasonPreempted // &ldquo;preempted&rdquo;
waitReasonDebugCall // &ldquo;debug call&rdquo;
)</p>
<p>M的信息如下：</p>
<ul>
<li>P: 当前与哪个P绑定</li>
<li>curg: 当前执行哪个G</li>
<li>gfreecnt: 可用的 G (Gdead state).</li>
<li>mallocing: 是否在分配内存</li>
<li>Throwing: 是否抛出了一场</li>
<li>preemptoff: 如果非空，当前执行的G不会被抢占</li>
</ul>
<p>P的信息如下：</p>
<ul>
<li>status: 运行状态</li>
<li>Schedule tick: 调度次数</li>
<li>syscalltick: 系统调用的次数</li>
<li>M: 与哪个M进行绑定</li>
<li>runqsize: 运行队列的大小</li>
<li>gfreecnt: 可用的 G (Gdead state).</li>
<li>P的状态表如下：</li>
</ul>
<p>const (
// P status
// _Pidle means a P is not being used to run user code or the
// scheduler. Typically, it&rsquo;s on the idle P list and available
// to the scheduler, but it may just be transitioning between
// other states.
//
// The P is owned by the idle list or by whatever is
// transitioning its state. Its run queue is empty.
_Pidle = iota
// _Prunning means a P is owned by an M and is being used to
// run user code or the scheduler. Only the M that owns this P
// is allowed to change the P&rsquo;s status from _Prunning. The M
// may transition the P to _Pidle (if it has no more work to
// do), _Psyscall (when entering a syscall), or _Pgcstop (to
// halt for the GC). The M may also hand ownership of the P
// off directly to another M (e.g., to schedule a locked G).
_Prunning
// _Psyscall means a P is not running user code. It has
// affinity to an M in a syscall but is not owned by it and
// may be stolen by another M. This is similar to _Pidle but
// uses lightweight transitions and maintains M affinity.
//
// Leaving _Psyscall must be done with a CAS, either to steal
// or retake the P. Note that there&rsquo;s an ABA hazard: even if
// an M successfully CASes its original P back to _Prunning
// after a syscall, it must understand the P may have been
// used by another M in the interim.
_Psyscall
// _Pgcstop means a P is halted for STW and owned by the M
// that stopped the world. The M that stopped the world
// continues to use its P, even in _Pgcstop. Transitioning
// from _Prunning to _Pgcstop causes an M to release its P and
// park.
//
// The P retains its run queue and startTheWorld will restart
// the scheduler on Ps with non-empty run queues.
_Pgcstop
// _Pdead means a P is no longer used (GOMAXPROCS shrank). We
// reuse Ps if GOMAXPROCS increases. A dead P is mostly
// stripped of its resources, though a few things remain
// (e.g., trace buffers).
_Pdead
)</p><div class="mt6 instapaper_ignoref">
</div>
</div>
<aside class="w-30-l mt6-l">
<div class="bg-light-gray pa3 nested-list-reset nested-copy-line-height nested-links">
<p class="f5 b mb3">Tags</p>
<ul class=pa0>
<li class=list>
<a href=/tags/golang class="link f5 grow no-underline br-pill ba ph3 pv2 mb2 dib black sans-serif">golang</a>
</li>
<li class=list>
<a href=/tags/%E8%B0%83%E5%BA%A6%E5%99%A8 class="link f5 grow no-underline br-pill ba ph3 pv2 mb2 dib black sans-serif">调度器</a>
</li>
</ul>
</div>
</aside>
</article>
</main>
<footer class="bg-black bottom-0 w-100 pa3" role=contentinfo>
<div class="flex justify-between">
<a class="f4 fw4 hover-white no-underline white-70 dn dib-ns pv2 ph3" href=https://tianyuxue.github.io/>
&copy; ACoder 2022
</a>
<div>
<div class=ananke-socials>
<a href=https://github.com/tianyuxue target=_blank class="github ananke-social-link link-transition stackoverflow link dib z-999 pt3 pt0-l mr1" title="GitHub link" rel=noopener aria-label="follow on GitHub——Opens in a new window">
<span class=icon><svg style="enable-background:new 0 0 512 512" viewBox="0 0 512 512" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M256 32C132.3 32 32 134.8 32 261.7c0 101.5 64.2 187.5 153.2 217.9 11.2 2.1 15.3-5 15.3-11.1.0-5.5-.2-19.9-.3-39.1-62.3 13.9-75.5-30.8-75.5-30.8-10.2-26.5-24.9-33.6-24.9-33.6-20.3-14.3 1.5-14 1.5-14 22.5 1.6 34.3 23.7 34.3 23.7 20 35.1 52.4 25 65.2 19.1 2-14.8 7.8-25 14.2-30.7-49.7-5.8-102-25.5-102-113.5.0-25.1 8.7-45.6 23-61.6-2.3-5.8-10-29.2 2.2-60.8.0.0 18.8-6.2 61.6 23.5 17.9-5.1 37-7.6 56.1-7.7 19 .1 38.2 2.6 56.1 7.7 42.8-29.7 61.5-23.5 61.5-23.5 12.2 31.6 4.5 55 2.2 60.8 14.3 16.1 23 36.6 23 61.6.0 88.2-52.4 107.6-102.3 113.3 8 7.1 15.2 21.1 15.2 42.5.0 30.7-.3 55.5-.3 63 0 6.1 4 13.3 15.4 11C415.9 449.1 480 363.1 480 261.7 480 134.8 379.7 32 256 32z"/></svg>
</span>
<span class=new-window><svg height="8" style="enable-background:new 0 0 1000 1000" viewBox="0 0 1e3 1e3" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"><path d="M598 128h298v298h-86V274L392 692l-60-60 418-418H598v-86zM810 810V512h86v298c0 46-40 86-86 86H214c-48 0-86-40-86-86V214c0-46 38-86 86-86h298v86H214v596h596z" style="fill-rule:evenodd;clip-rule:evenodd;fill:"/></svg>
</span></a>
</div></div>
</div>
</footer>
</body>
</html>